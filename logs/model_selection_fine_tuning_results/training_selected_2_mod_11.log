
Dataset loaded:
Shape of training set (example, time, channels): (20812, 500, 61)
Shape of test set (example, time, channels): (3989, 500, 61)
Shape of train validation set (example, time, channels): (2313, 500, 61)
Shape of test validation set (example, time, channels): (1710, 500, 61)
Num of classes in all: 25

Creating model based on ../configuration/hyperparameter_combinations/selected/selected_2_mod_11.json hyperparameter file 

Adding feature wise convolutions with 32 filters per feature, 3 kernels and 1 strides ...
Adding feature wise convolutions with 1 filters per feature, 3 kernels and 1 strides ...
Adding feature based graph attention layer ...
Adding time based graph attention layer ...
Adding GRU layer with 256 units ...
Adding GRU layer with 61 units ...
Adding dense layer to forecasting model with 512 units and ReLu activation ...
Adding dense layer to forecasting model with 256 units and ReLu activation ...
Adding last dense layer to forecasting model with 61 units and sigmoid activation ...
Adding VAE as reconstruction model with dimensions 3072 & 1536 and ...
The RBM reconstructs the output of the gru layer.

Epoch 0
	Step 0: mean loss = 1.3120
	Step 50: mean loss = 0.6853
	Step 100: mean loss = 0.5063
	Step 150: mean loss = 0.4054

	Loss on validation set after epoch 0: 0.1459

Epoch 1
	Step 0: mean loss = 0.1442
	Step 50: mean loss = 0.1387
	Step 100: mean loss = 0.1332
	Step 150: mean loss = 0.1285

	Loss on validation set after epoch 1: 0.1139

Epoch 2
	Step 0: mean loss = 0.1152
	Step 50: mean loss = 0.1106
	Step 100: mean loss = 0.1083
	Step 150: mean loss = 0.1060

	Loss on validation set after epoch 2: 0.0982

Epoch 3
	Step 0: mean loss = 0.1028
	Step 50: mean loss = 0.0963
	Step 100: mean loss = 0.0946
	Step 150: mean loss = 0.0931

	Loss on validation set after epoch 3: 0.0875

Epoch 4
	Step 0: mean loss = 0.0904
	Step 50: mean loss = 0.0857
	Step 100: mean loss = 0.0845
	Step 150: mean loss = 0.0833

	Loss on validation set after epoch 4: 0.0798

Epoch 5
	Step 0: mean loss = 0.0785
	Step 50: mean loss = 0.0780
	Step 100: mean loss = 0.0774
	Step 150: mean loss = 0.0766

	Loss on validation set after epoch 5: 0.0744

Epoch 6
	Step 0: mean loss = 0.0728
	Step 50: mean loss = 0.0727
	Step 100: mean loss = 0.0723
	Step 150: mean loss = 0.0717

	Loss on validation set after epoch 6: 0.0690

Epoch 7
	Step 0: mean loss = 0.0718
	Step 50: mean loss = 0.0680
	Step 100: mean loss = 0.0672
	Step 150: mean loss = 0.0667

	Loss on validation set after epoch 7: 0.0650

Epoch 8
	Step 0: mean loss = 0.0605
	Step 50: mean loss = 0.0638
	Step 100: mean loss = 0.0635
	Step 150: mean loss = 0.0631

	Loss on validation set after epoch 8: 0.0604

Epoch 9
	Step 0: mean loss = 0.0586
	Step 50: mean loss = 0.0611
	Step 100: mean loss = 0.0610
	Step 150: mean loss = 0.0608

	Loss on validation set after epoch 9: 0.0591

Epoch 10
	Step 0: mean loss = 0.0560
	Step 50: mean loss = 0.0592
	Step 100: mean loss = 0.0592
	Step 150: mean loss = 0.0590

	Loss on validation set after epoch 10: 0.0571

Epoch 11
	Step 0: mean loss = 0.0586
	Step 50: mean loss = 0.0576
	Step 100: mean loss = 0.0579
	Step 150: mean loss = 0.0577

	Loss on validation set after epoch 11: 0.0564

Epoch 12
	Step 0: mean loss = 0.0566
	Step 50: mean loss = 0.0566
	Step 100: mean loss = 0.0566
	Step 150: mean loss = 0.0565

	Loss on validation set after epoch 12: 0.0558

Epoch 13
	Step 0: mean loss = 0.0561
	Step 50: mean loss = 0.0556
	Step 100: mean loss = 0.0559
	Step 150: mean loss = 0.0557

	Loss on validation set after epoch 13: 0.0547

Epoch 14
	Step 0: mean loss = 0.0614
	Step 50: mean loss = 0.0550
	Step 100: mean loss = 0.0550
	Step 150: mean loss = 0.0547

	Loss on validation set after epoch 14: 0.0535

Epoch 15
	Step 0: mean loss = 0.0519
	Step 50: mean loss = 0.0540
	Step 100: mean loss = 0.0539
	Step 150: mean loss = 0.0539

	Loss on validation set after epoch 15: 0.0524

Epoch 16
	Step 0: mean loss = 0.0520
	Step 50: mean loss = 0.0534
	Step 100: mean loss = 0.0536
	Step 150: mean loss = 0.0535

	Loss on validation set after epoch 16: 0.0514

Epoch 17
	Step 0: mean loss = 0.0532
	Step 50: mean loss = 0.0520
	Step 100: mean loss = 0.0522
	Step 150: mean loss = 0.0521

	Loss on validation set after epoch 17: 0.0523

Epoch 18
	Step 0: mean loss = 0.0543
	Step 50: mean loss = 0.0514
	Step 100: mean loss = 0.0512
	Step 150: mean loss = 0.0511

	Loss on validation set after epoch 18: 0.0506

Epoch 19
	Step 0: mean loss = 0.0509
	Step 50: mean loss = 0.0501
	Step 100: mean loss = 0.0500
	Step 150: mean loss = 0.0497

	Loss on validation set after epoch 19: 0.0485

Epoch 20
	Step 0: mean loss = 0.0463
	Step 50: mean loss = 0.0485
	Step 100: mean loss = 0.0483
	Step 150: mean loss = 0.0480

	Loss on validation set after epoch 20: 0.0466

Epoch 21
	Step 0: mean loss = 0.0462
	Step 50: mean loss = 0.0466
	Step 100: mean loss = 0.0462
	Step 150: mean loss = 0.0459

	Loss on validation set after epoch 21: 0.0448

Epoch 22
	Step 0: mean loss = 0.0455
	Step 50: mean loss = 0.0443
	Step 100: mean loss = 0.0444
	Step 150: mean loss = 0.0444

	Loss on validation set after epoch 22: 0.0437

Epoch 23
	Step 0: mean loss = 0.0413
	Step 50: mean loss = 0.0433
	Step 100: mean loss = 0.0432
	Step 150: mean loss = 0.0431

	Loss on validation set after epoch 23: 0.0424

Epoch 24
	Step 0: mean loss = 0.0437
	Step 50: mean loss = 0.0424
	Step 100: mean loss = 0.0425
	Step 150: mean loss = 0.0423

	Loss on validation set after epoch 24: 0.0427

Epoch 25
	Step 0: mean loss = 0.0456
	Step 50: mean loss = 0.0416
	Step 100: mean loss = 0.0417
	Step 150: mean loss = 0.0417

	Loss on validation set after epoch 25: 0.0409

Epoch 26
	Step 0: mean loss = 0.0403
	Step 50: mean loss = 0.0413
	Step 100: mean loss = 0.0413
	Step 150: mean loss = 0.0411

	Loss on validation set after epoch 26: 0.0398

Epoch 27
	Step 0: mean loss = 0.0437
	Step 50: mean loss = 0.0404
	Step 100: mean loss = 0.0405
	Step 150: mean loss = 0.0404

	Loss on validation set after epoch 27: 0.0405

Epoch 28
	Step 0: mean loss = 0.0394
	Step 50: mean loss = 0.0399
	Step 100: mean loss = 0.0400
	Step 150: mean loss = 0.0401

	Loss on validation set after epoch 28: 0.0399

Epoch 29
	Step 0: mean loss = 0.0380
	Step 50: mean loss = 0.0394
	Step 100: mean loss = 0.0394
	Step 150: mean loss = 0.0394

	Loss on validation set after epoch 29: 0.0396

Epoch 30
	Step 0: mean loss = 0.0408
	Step 50: mean loss = 0.0393
	Step 100: mean loss = 0.0391
	Step 150: mean loss = 0.0390

	Loss on validation set after epoch 30: 0.0382

Epoch 31
	Step 0: mean loss = 0.0398
	Step 50: mean loss = 0.0387
	Step 100: mean loss = 0.0386
	Step 150: mean loss = 0.0385

	Loss on validation set after epoch 31: 0.0381

Epoch 32
	Step 0: mean loss = 0.0420
	Step 50: mean loss = 0.0379
	Step 100: mean loss = 0.0380
	Step 150: mean loss = 0.0380

	Loss on validation set after epoch 32: 0.0379

Epoch 33
	Step 0: mean loss = 0.0435
	Step 50: mean loss = 0.0377
	Step 100: mean loss = 0.0375
	Step 150: mean loss = 0.0376

	Loss on validation set after epoch 33: 0.0373

Epoch 34
	Step 0: mean loss = 0.0345
	Step 50: mean loss = 0.0372
	Step 100: mean loss = 0.0371
	Step 150: mean loss = 0.0370

	Loss on validation set after epoch 34: 0.0367

Epoch 35
	Step 0: mean loss = 0.0382
	Step 50: mean loss = 0.0369
	Step 100: mean loss = 0.0369
	Step 150: mean loss = 0.0367

	Loss on validation set after epoch 35: 0.0365

Epoch 36
	Step 0: mean loss = 0.0379
	Step 50: mean loss = 0.0365
	Step 100: mean loss = 0.0364
	Step 150: mean loss = 0.0363

	Loss on validation set after epoch 36: 0.0366

Epoch 37
	Step 0: mean loss = 0.0367
	Step 50: mean loss = 0.0360
	Step 100: mean loss = 0.0359
	Step 150: mean loss = 0.0359

	Loss on validation set after epoch 37: 0.0362

Epoch 38
	Step 0: mean loss = 0.0383
	Step 50: mean loss = 0.0359
	Step 100: mean loss = 0.0355
	Step 150: mean loss = 0.0354

	Loss on validation set after epoch 38: 0.0348

Epoch 39
	Step 0: mean loss = 0.0334
	Step 50: mean loss = 0.0353
	Step 100: mean loss = 0.0351
	Step 150: mean loss = 0.0349

	Loss on validation set after epoch 39: 0.0350

Epoch 40
	Step 0: mean loss = 0.0353
	Step 50: mean loss = 0.0346
	Step 100: mean loss = 0.0346
	Step 150: mean loss = 0.0344

	Loss on validation set after epoch 40: 0.0349

Epoch 41
	Step 0: mean loss = 0.0348
	Step 50: mean loss = 0.0341
	Step 100: mean loss = 0.0340
	Step 150: mean loss = 0.0340

	Loss on validation set after epoch 41: 0.0336

Epoch 42
	Step 0: mean loss = 0.0364
	Step 50: mean loss = 0.0336
	Step 100: mean loss = 0.0336
	Step 150: mean loss = 0.0335

	Loss on validation set after epoch 42: 0.0327

Epoch 43
	Step 0: mean loss = 0.0338
	Step 50: mean loss = 0.0330
	Step 100: mean loss = 0.0330
	Step 150: mean loss = 0.0328

	Loss on validation set after epoch 43: 0.0328

Epoch 44
	Step 0: mean loss = 0.0312
	Step 50: mean loss = 0.0325
	Step 100: mean loss = 0.0324
	Step 150: mean loss = 0.0324

	Loss on validation set after epoch 44: 0.0328

Epoch 45
	Step 0: mean loss = 0.0340
	Step 50: mean loss = 0.0320
	Step 100: mean loss = 0.0320
	Step 150: mean loss = 0.0318

	Loss on validation set after epoch 45: 0.0325

Epoch 46
	Step 0: mean loss = 0.0342
	Step 50: mean loss = 0.0313
	Step 100: mean loss = 0.0313
	Step 150: mean loss = 0.0312

	Loss on validation set after epoch 46: 0.0307

Epoch 47
	Step 0: mean loss = 0.0308
	Step 50: mean loss = 0.0306
	Step 100: mean loss = 0.0309
	Step 150: mean loss = 0.0308

	Loss on validation set after epoch 47: 0.0312

Epoch 48
	Step 0: mean loss = 0.0293
	Step 50: mean loss = 0.0301
	Step 100: mean loss = 0.0302
	Step 150: mean loss = 0.0302

	Loss on validation set after epoch 48: 0.0303

Epoch 49
	Step 0: mean loss = 0.0282
	Step 50: mean loss = 0.0297
	Step 100: mean loss = 0.0297
	Step 150: mean loss = 0.0296

	Loss on validation set after epoch 49: 0.0294

Epoch 50
	Step 0: mean loss = 0.0303
	Step 50: mean loss = 0.0291
	Step 100: mean loss = 0.0292
	Step 150: mean loss = 0.0292

	Loss on validation set after epoch 50: 0.0287

Epoch 51
	Step 0: mean loss = 0.0249
	Step 50: mean loss = 0.0292
	Step 100: mean loss = 0.0291
	Step 150: mean loss = 0.0289

	Loss on validation set after epoch 51: 0.0294

Epoch 52
	Step 0: mean loss = 0.0235
	Step 50: mean loss = 0.0280
	Step 100: mean loss = 0.0282
	Step 150: mean loss = 0.0283

	Loss on validation set after epoch 52: 0.0282

Epoch 53
	Step 0: mean loss = 0.0313
	Step 50: mean loss = 0.0279
	Step 100: mean loss = 0.0278
	Step 150: mean loss = 0.0278

	Loss on validation set after epoch 53: 0.0272

Epoch 54
	Step 0: mean loss = 0.0294
	Step 50: mean loss = 0.0274
	Step 100: mean loss = 0.0275
	Step 150: mean loss = 0.0276

	Loss on validation set after epoch 54: 0.0265

Epoch 55
	Step 0: mean loss = 0.0306
	Step 50: mean loss = 0.0269
	Step 100: mean loss = 0.0269
	Step 150: mean loss = 0.0271

	Loss on validation set after epoch 55: 0.0269

Epoch 56
	Step 0: mean loss = 0.0268
	Step 50: mean loss = 0.0273
	Step 100: mean loss = 0.0272
	Step 150: mean loss = 0.0270

	Loss on validation set after epoch 56: 0.0270

Epoch 57
	Step 0: mean loss = 0.0266
	Step 50: mean loss = 0.0266
	Step 100: mean loss = 0.0265
	Step 150: mean loss = 0.0264

	Loss on validation set after epoch 57: 0.0257

Epoch 58
	Step 0: mean loss = 0.0238
	Step 50: mean loss = 0.0258
	Step 100: mean loss = 0.0261
	Step 150: mean loss = 0.0261

	Loss on validation set after epoch 58: 0.0263

Epoch 59
	Step 0: mean loss = 0.0249
	Step 50: mean loss = 0.0259
	Step 100: mean loss = 0.0258
	Step 150: mean loss = 0.0258

	Loss on validation set after epoch 59: 0.0261

Epoch 60
	Step 0: mean loss = 0.0275
	Step 50: mean loss = 0.0255
	Step 100: mean loss = 0.0255
	Step 150: mean loss = 0.0255

	Loss on validation set after epoch 60: 0.0253

Epoch 61
	Step 0: mean loss = 0.0274
	Step 50: mean loss = 0.0255
	Step 100: mean loss = 0.0254
	Step 150: mean loss = 0.0254

	Loss on validation set after epoch 61: 0.0252

Epoch 62
	Step 0: mean loss = 0.0263
	Step 50: mean loss = 0.0258
	Step 100: mean loss = 0.0254
	Step 150: mean loss = 0.0254

	Loss on validation set after epoch 62: 0.0250

Epoch 63
	Step 0: mean loss = 0.0271
	Step 50: mean loss = 0.0249
	Step 100: mean loss = 0.0250
	Step 150: mean loss = 0.0250

	Loss on validation set after epoch 63: 0.0243

Epoch 64
	Step 0: mean loss = 0.0239
	Step 50: mean loss = 0.0246
	Step 100: mean loss = 0.0248
	Step 150: mean loss = 0.0248

	Loss on validation set after epoch 64: 0.0244

Epoch 65
	Step 0: mean loss = 0.0259
	Step 50: mean loss = 0.0243
	Step 100: mean loss = 0.0247
	Step 150: mean loss = 0.0246

	Loss on validation set after epoch 65: 0.0243

Epoch 66
	Step 0: mean loss = 0.0216
	Step 50: mean loss = 0.0242
	Step 100: mean loss = 0.0244
	Step 150: mean loss = 0.0243

	Loss on validation set after epoch 66: 0.0249

Epoch 67
	Step 0: mean loss = 0.0256
	Step 50: mean loss = 0.0237
	Step 100: mean loss = 0.0239
	Step 150: mean loss = 0.0240

	Loss on validation set after epoch 67: 0.0252

Epoch 68
	Step 0: mean loss = 0.0312
	Step 50: mean loss = 0.0237
	Step 100: mean loss = 0.0241
	Step 150: mean loss = 0.0240

	Loss on validation set after epoch 68: 0.0237

Epoch 69
	Step 0: mean loss = 0.0260
	Step 50: mean loss = 0.0236
	Step 100: mean loss = 0.0236
	Step 150: mean loss = 0.0235

	Loss on validation set after epoch 69: 0.0229

Epoch 70
	Step 0: mean loss = 0.0211
	Step 50: mean loss = 0.0230
	Step 100: mean loss = 0.0231
	Step 150: mean loss = 0.0231

	Loss on validation set after epoch 70: 0.0235

Epoch 71
	Step 0: mean loss = 0.0239
	Step 50: mean loss = 0.0227
	Step 100: mean loss = 0.0227
	Step 150: mean loss = 0.0227

	Loss on validation set after epoch 71: 0.0230

Epoch 72
	Step 0: mean loss = 0.0200
	Step 50: mean loss = 0.0228
	Step 100: mean loss = 0.0226
	Step 150: mean loss = 0.0227

	Loss on validation set after epoch 72: 0.0229

Epoch 73
	Step 0: mean loss = 0.0230
	Step 50: mean loss = 0.0226
	Step 100: mean loss = 0.0225
	Step 150: mean loss = 0.0226

	Loss on validation set after epoch 73: 0.0223

Epoch 74
	Step 0: mean loss = 0.0229
	Step 50: mean loss = 0.0224
	Step 100: mean loss = 0.0225
	Step 150: mean loss = 0.0225

	Loss on validation set after epoch 74: 0.0222

Epoch 75
	Step 0: mean loss = 0.0222
	Step 50: mean loss = 0.0223
	Step 100: mean loss = 0.0222
	Step 150: mean loss = 0.0225

	Loss on validation set after epoch 75: 0.0234

Epoch 76
	Step 0: mean loss = 0.0213
	Step 50: mean loss = 0.0219
	Step 100: mean loss = 0.0220
	Step 150: mean loss = 0.0220

	Loss on validation set after epoch 76: 0.0225

Epoch 77
	Step 0: mean loss = 0.0231
	Step 50: mean loss = 0.0218
	Step 100: mean loss = 0.0219
	Step 150: mean loss = 0.0219

	Loss on validation set after epoch 77: 0.0225

Epoch 78
	Step 0: mean loss = 0.0228
	Step 50: mean loss = 0.0216
	Step 100: mean loss = 0.0218
	Step 150: mean loss = 0.0220

	Loss on validation set after epoch 78: 0.0214

Epoch 79
	Step 0: mean loss = 0.0190
	Step 50: mean loss = 0.0221
	Step 100: mean loss = 0.0221
	Step 150: mean loss = 0.0220

	Loss on validation set after epoch 79: 0.0222

Epoch 80
	Step 0: mean loss = 0.0217
	Step 50: mean loss = 0.0214
	Step 100: mean loss = 0.0216
	Step 150: mean loss = 0.0216

	Loss on validation set after epoch 80: 0.0210

Epoch 81
	Step 0: mean loss = 0.0211
	Step 50: mean loss = 0.0212
	Step 100: mean loss = 0.0214
	Step 150: mean loss = 0.0214

	Loss on validation set after epoch 81: 0.0235

Epoch 82
	Step 0: mean loss = 0.0209
	Step 50: mean loss = 0.0213
	Step 100: mean loss = 0.0218
	Step 150: mean loss = 0.0217

	Loss on validation set after epoch 82: 0.0215

Epoch 83
	Step 0: mean loss = 0.0237
	Step 50: mean loss = 0.0210
	Step 100: mean loss = 0.0212
	Step 150: mean loss = 0.0211

	Loss on validation set after epoch 83: 0.0209

Epoch 84
	Step 0: mean loss = 0.0201
	Step 50: mean loss = 0.0208
	Step 100: mean loss = 0.0210
	Step 150: mean loss = 0.0211

	Loss on validation set after epoch 84: 0.0214

Epoch 85
	Step 0: mean loss = 0.0216
	Step 50: mean loss = 0.0210
	Step 100: mean loss = 0.0210
	Step 150: mean loss = 0.0211

	Loss on validation set after epoch 85: 0.0212

Epoch 86
	Step 0: mean loss = 0.0232
	Step 50: mean loss = 0.0208
	Step 100: mean loss = 0.0208
	Step 150: mean loss = 0.0207

	Loss on validation set after epoch 86: 0.0205

Epoch 87
	Step 0: mean loss = 0.0216
	Step 50: mean loss = 0.0208
	Step 100: mean loss = 0.0212
	Step 150: mean loss = 0.0211

	Loss on validation set after epoch 87: 0.0217

Epoch 88
	Step 0: mean loss = 0.0215
	Step 50: mean loss = 0.0205
	Step 100: mean loss = 0.0206
	Step 150: mean loss = 0.0206

	Loss on validation set after epoch 88: 0.0205

Epoch 89
	Step 0: mean loss = 0.0208
	Step 50: mean loss = 0.0204
	Step 100: mean loss = 0.0205
	Step 150: mean loss = 0.0204

	Loss on validation set after epoch 89: 0.0202

Epoch 90
	Step 0: mean loss = 0.0203
	Step 50: mean loss = 0.0202
	Step 100: mean loss = 0.0201
	Step 150: mean loss = 0.0202

	Loss on validation set after epoch 90: 0.0223

Epoch 91
	Step 0: mean loss = 0.0221
	Step 50: mean loss = 0.0203
	Step 100: mean loss = 0.0204
	Step 150: mean loss = 0.0204

	Loss on validation set after epoch 91: 0.0198

Epoch 92
	Step 0: mean loss = 0.0199
	Step 50: mean loss = 0.0200
	Step 100: mean loss = 0.0201
	Step 150: mean loss = 0.0200

	Loss on validation set after epoch 92: 0.0199

Epoch 93
	Step 0: mean loss = 0.0190
	Step 50: mean loss = 0.0200
	Step 100: mean loss = 0.0199
	Step 150: mean loss = 0.0199

	Loss on validation set after epoch 93: 0.0199

Epoch 94
	Step 0: mean loss = 0.0181
	Step 50: mean loss = 0.0198
	Step 100: mean loss = 0.0198
	Step 150: mean loss = 0.0199

	Loss on validation set after epoch 94: 0.0194

Epoch 95
	Step 0: mean loss = 0.0205
	Step 50: mean loss = 0.0198
	Step 100: mean loss = 0.0198
	Step 150: mean loss = 0.0198

	Loss on validation set after epoch 95: 0.0193

Epoch 96
	Step 0: mean loss = 0.0162
	Step 50: mean loss = 0.0197
	Step 100: mean loss = 0.0198
	Step 150: mean loss = 0.0200

	Loss on validation set after epoch 96: 0.0199

Epoch 97
	Step 0: mean loss = 0.0197
	Step 50: mean loss = 0.0197
	Step 100: mean loss = 0.0200
	Step 150: mean loss = 0.0198

	Loss on validation set after epoch 97: 0.0194

Epoch 98
	Step 0: mean loss = 0.0221
	Step 50: mean loss = 0.0195
	Step 100: mean loss = 0.0196
	Step 150: mean loss = 0.0195

	Loss on validation set after epoch 98: 0.0196

Epoch 99
	Step 0: mean loss = 0.0176
	Step 50: mean loss = 0.0193
	Step 100: mean loss = 0.0196
	Step 150: mean loss = 0.0195

	Loss on validation set after epoch 99: 0.0193

Epoch 100
	Step 0: mean loss = 0.0201
	Step 50: mean loss = 0.0191
	Step 100: mean loss = 0.0193
	Step 150: mean loss = 0.0193

	Loss on validation set after epoch 100: 0.0187

Epoch 101
	Step 0: mean loss = 0.0223
	Step 50: mean loss = 0.0193
	Step 100: mean loss = 0.0199
	Step 150: mean loss = 0.0197

	Loss on validation set after epoch 101: 0.0187

Epoch 102
	Step 0: mean loss = 0.0196
	Step 50: mean loss = 0.0189
	Step 100: mean loss = 0.0190
	Step 150: mean loss = 0.0190

	Loss on validation set after epoch 102: 0.0192

Epoch 103
	Step 0: mean loss = 0.0185
	Step 50: mean loss = 0.0196
	Step 100: mean loss = 0.0193
	Step 150: mean loss = 0.0192

	Loss on validation set after epoch 103: 0.0181

Epoch 104
	Step 0: mean loss = 0.0170
	Step 50: mean loss = 0.0190
	Step 100: mean loss = 0.0191
	Step 150: mean loss = 0.0190

	Loss on validation set after epoch 104: 0.0185

Epoch 105
	Step 0: mean loss = 0.0223
	Step 50: mean loss = 0.0188
	Step 100: mean loss = 0.0189
	Step 150: mean loss = 0.0188

	Loss on validation set after epoch 105: 0.0187

Epoch 106
	Step 0: mean loss = 0.0184
	Step 50: mean loss = 0.0189
	Step 100: mean loss = 0.0189
	Step 150: mean loss = 0.0189

	Loss on validation set after epoch 106: 0.0184

Epoch 107
	Step 0: mean loss = 0.0180
	Step 50: mean loss = 0.0189
	Step 100: mean loss = 0.0189
	Step 150: mean loss = 0.0187

	Loss on validation set after epoch 107: 0.0186

Epoch 108
	Step 0: mean loss = 0.0204
	Step 50: mean loss = 0.0188
	Step 100: mean loss = 0.0187
	Step 150: mean loss = 0.0186

	Loss on validation set after epoch 108: 0.0186

Epoch 109
	Step 0: mean loss = 0.0180
	Step 50: mean loss = 0.0185
	Step 100: mean loss = 0.0187
	Step 150: mean loss = 0.0186

	Loss on validation set after epoch 109: 0.0187

Model from epoch 103 was selected by early stopping.
Training process will be stopped now.
Deleted temporary files in ../data/trained_models/temp_02-14-15-32-11/
Location of saved model: ../data/trained_models/selected_2_mod_11_02-14-15-32-11/ 

Adding feature wise convolutions with 32 filters per feature, 3 kernels and 1 strides ...
Adding feature wise convolutions with 1 filters per feature, 3 kernels and 1 strides ...
Adding feature based graph attention layer ...
Adding time based graph attention layer ...
Adding GRU layer with 256 units ...
Adding GRU layer with 61 units ...
Adding dense layer to forecasting model with 512 units and ReLu activation ...
Adding dense layer to forecasting model with 256 units and ReLu activation ...
Adding last dense layer to forecasting model with 61 units and sigmoid activation ...
Adding VAE as reconstruction model with dimensions 3072 & 1536 and ...
The RBM reconstructs the output of the gru layer.

Grid search running in anomaly detection model selection mode.
The following hyperparameters will not be evaluated:
relevance_mapping
unaffected_component_threshold
si_mode
si_parameter

Testing 8874 combinations via grid search 
for model selected_2_mod_11_02-14-15-32-11/ on the validation dataset. 


Best combinations tested:
      gamma  single_timestamp_a.. affected_timestamp..     AD F1     AD F2    AD TPR   AD Prec    AD ACC    AD TNR    AD FPR  SI/ST AVG-HR@100%  SI/ST AVG-HR@150%  SI/ST AVG-HR@K  SI/ST F1  SI/ST TPR  SI/ST ACC
Comb                                                                                                                                                                                                              
2898   0.35                  0.28                  230  0.680916  0.684049  0.686154  0.675758  0.877778  0.922744  0.077256           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
5074   0.55                  0.31                  240  0.679525  0.694360  0.704615  0.656160  0.873684  0.913357  0.086643           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2899   0.35                  0.28                  240  0.678955  0.679582  0.680000  0.677914  0.877778  0.924188  0.075812           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2348   0.30                  0.27                  240  0.676602  0.689550  0.698462  0.656069  0.873099  0.914079  0.085921           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
2347   0.30                  0.27                  230  0.676558  0.691328  0.701538  0.653295  0.872515  0.912635  0.087365           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
5073   0.55                  0.31                  230  0.676514  0.693099  0.704615  0.650568  0.871930  0.911191  0.088809           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2897   0.35                  0.28                  220  0.675716  0.683761  0.689231  0.662722  0.874269  0.917690  0.082310           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2894   0.35                  0.28                  195  0.673591  0.688296  0.698462  0.650430  0.871345  0.911913  0.088087           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2896   0.35                  0.28                  210  0.672646  0.684307  0.692308  0.654070  0.871930  0.914079  0.085921           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2895   0.35                  0.28                  200  0.672619  0.686096  0.695385  0.651297  0.871345  0.912635  0.087365           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
5072   0.55                  0.31                  220  0.672515  0.693189  0.707692  0.640669  0.869006  0.906859  0.093141           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
5071   0.55                  0.31                  210  0.672489  0.694946  0.710769  0.638122  0.868421  0.905415  0.094585           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
3437   0.40                  0.29                  155  0.670659  0.681680  0.689231  0.653061  0.871345  0.914079  0.085921           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3435   0.40                  0.29                  145  0.670641  0.683475  0.692308  0.650289  0.870760  0.912635  0.087365           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3436   0.40                  0.29                  150  0.670641  0.683475  0.692308  0.650289  0.870760  0.912635  0.087365           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3434   0.40                  0.29                  140  0.670623  0.685264  0.695385  0.647564  0.870175  0.911191  0.088809           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
1797   0.25                  0.26                  240  0.670606  0.687046  0.698462  0.644886  0.869591  0.909747  0.090253           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
2893   0.35                  0.28                  190  0.670606  0.687046  0.698462  0.644886  0.869591  0.909747  0.090253           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
5069   0.55                  0.31                  195  0.670537  0.694111  0.710769  0.634615  0.867251  0.903971  0.096029           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
5070   0.55                  0.31                  200  0.670537  0.694111  0.710769  0.634615  0.867251  0.903971  0.096029           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
5068   0.55                  0.31                  190  0.670520  0.695861  0.713846  0.632153  0.866667  0.902527  0.097473           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2892   0.35                  0.28                  185  0.669604  0.688406  0.701538  0.640449  0.868421  0.907581  0.092419           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
3448   0.40                  0.29                  220  0.668750  0.662539  0.658462  0.679365  0.876023  0.927076  0.072924           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3433   0.40                  0.29                  135  0.668630  0.686215  0.698462  0.641243  0.868421  0.908303  0.091697           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
2346   0.30                  0.27                  220  0.668622  0.687990  0.701538  0.638655  0.867836  0.906859  0.093141           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
3449   0.40                  0.29                  230  0.667712  0.660260  0.655385  0.680511  0.876023  0.927798  0.072202           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3443   0.40                  0.29                  185  0.667688  0.669533  0.670769  0.664634  0.873099  0.920578  0.079422           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
6697   0.70                  0.33                  230  0.667683  0.671367  0.673846  0.661631  0.872515  0.919134  0.080866           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6696   0.70                  0.33                  220  0.667678  0.673195  0.676923  0.658683  0.871930  0.917690  0.082310           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6695   0.70                  0.33                  210  0.667674  0.675015  0.680000  0.655786  0.871345  0.916245  0.083755           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
3439   0.40                  0.29                  165  0.667669  0.676829  0.683077  0.652941  0.870760  0.914801  0.085199           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
7770   0.80                  0.34                  230  0.667669  0.676829  0.683077  0.652941  0.870760  0.914801  0.085199           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3432   0.40                  0.29                  130  0.667643  0.687575  0.701538  0.636872  0.867251  0.906137  0.093863           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
5067   0.55                  0.31                  185  0.666667  0.694195  0.713846  0.625337  0.864327  0.899639  0.100361           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
1246   0.20                  0.25                  240  0.666667  0.681818  0.692308  0.642857  0.868421  0.909747  0.090253           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
3438   0.40                  0.29                  160  0.666667  0.676417  0.683077  0.651026  0.870175  0.914079  0.085921           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
6694   0.70                  0.33                  200  0.666667  0.676417  0.683077  0.651026  0.870175  0.914079  0.085921           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
3442   0.40                  0.29                  180  0.666667  0.670956  0.673846  0.659639  0.871930  0.918412  0.081588           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
1245   0.20                  0.25                  230  0.665680  0.681405  0.692308  0.641026  0.867836  0.909025  0.090975           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
6692   0.70                  0.33                  190  0.665667  0.676005  0.683077  0.649123  0.869591  0.913357  0.086643           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6693   0.70                  0.33                  195  0.665667  0.676005  0.683077  0.649123  0.869591  0.913357  0.086643           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
3440   0.40                  0.29                  170  0.665658  0.672372  0.676923  0.654762  0.870760  0.916245  0.083755           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3441   0.40                  0.29                  175  0.665658  0.672372  0.676923  0.654762  0.870760  0.916245  0.083755           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
2890   0.35                  0.28                  175  0.664731  0.688101  0.704615  0.629121  0.864912  0.902527  0.097473           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
1796   0.25                  0.26                  230  0.664723  0.686334  0.701538  0.631579  0.865497  0.903971  0.096029           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
3431   0.40                  0.29                  125  0.664723  0.686334  0.701538  0.631579  0.865497  0.903971  0.096029           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
7769   0.80                  0.34                  220  0.664680  0.677400  0.686154  0.644509  0.868421  0.911191  0.088809           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
7771   0.80                  0.34                  240  0.664643  0.670135  0.673846  0.655689  0.870760  0.916968  0.083032           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
2891   0.35                  0.28                  180  0.663755  0.685921  0.701538  0.629834  0.864912  0.903249  0.096751           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
6691   0.70                  0.33                  185  0.663690  0.676988  0.686154  0.642651  0.867836  0.910469  0.089531           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
3447   0.40                  0.29                  210  0.663580  0.662354  0.661538  0.665635  0.872515  0.922022  0.077978           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
7220   0.75                  0.33                  240  0.663172  0.727848  0.778462  0.577626  0.849708  0.866426  0.133574           0.229562           0.351939        0.141538  0.055385   0.055385   0.854675
5066   0.55                  0.31                  180  0.662857  0.692537  0.713846  0.618667  0.861988  0.896751  0.103249           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2889   0.35                  0.28                  170  0.662808  0.687275  0.704615  0.625683  0.863743  0.901083  0.098917           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
8293   0.85                  0.34                  240  0.662338  0.730659  0.784615  0.573034  0.847953  0.862816  0.137184           0.218262           0.334946        0.144615  0.052308   0.052308   0.854201
4523   0.50                  0.30                  240  0.662088  0.707575  0.741538  0.598015  0.856140  0.883032  0.116968           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
6147   0.65                  0.32                  240  0.662069  0.705882  0.738462  0.600000  0.856725  0.884477  0.115523           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
3429   0.40                  0.29                  115  0.661871  0.688623  0.707692  0.621622  0.862573  0.898917  0.101083           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
6690   0.70                  0.33                  180  0.661721  0.676167  0.686154  0.638968  0.866667  0.909025  0.090975           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
7768   0.80                  0.34                  210  0.661721  0.676167  0.686154  0.638968  0.866667  0.909025  0.090975           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3444   0.40                  0.29                  190  0.661538  0.661538  0.661538  0.661538  0.871345  0.920578  0.079422           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3445   0.40                  0.29                  195  0.661538  0.661538  0.661538  0.661538  0.871345  0.920578  0.079422           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3446   0.40                  0.29                  200  0.661538  0.661538  0.661538  0.661538  0.871345  0.920578  0.079422           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
2345   0.30                  0.27                  210  0.660870  0.684685  0.701538  0.624658  0.863158  0.901083  0.098917           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
3430   0.40                  0.29                  120  0.660870  0.684685  0.701538  0.624658  0.863158  0.901083  0.098917           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
6698   0.70                  0.33                  240  0.660494  0.659273  0.658462  0.662539  0.871345  0.921300  0.078700           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6145   0.65                  0.32                  220  0.660326  0.710111  0.747692  0.591241  0.853801  0.878700  0.121300           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
6146   0.65                  0.32                  230  0.660274  0.706745  0.741538  0.595062  0.854971  0.881588  0.118412           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
2887   0.35                  0.28                  160  0.660000  0.689552  0.710769  0.616000  0.860819  0.896029  0.103971           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2888   0.35                  0.28                  165  0.659942  0.686040  0.704615  0.620596  0.861988  0.898917  0.101083           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2344   0.30                  0.27                  200  0.659913  0.684274  0.701538  0.622951  0.862573  0.900361  0.099639           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
1244   0.20                  0.25                  220  0.659854  0.680723  0.695385  0.627778  0.863743  0.903249  0.096751           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
3450   0.40                  0.29                  240  0.659271  0.647572  0.640000  0.679739  0.874269  0.929242  0.070758           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
5065   0.55                  0.31                  175  0.659123  0.692628  0.716923  0.609948  0.859064  0.892419  0.107581           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2342   0.30                  0.27                  190  0.659026  0.687388  0.707692  0.616622  0.860819  0.896751  0.103249           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
3428   0.40                  0.29                  110  0.659026  0.687388  0.707692  0.616622  0.860819  0.896751  0.103249           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
1795   0.25                  0.26                  220  0.658960  0.683863  0.701538  0.621253  0.861988  0.899639  0.100361           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
2886   0.35                  0.28                  155  0.658120  0.688730  0.710769  0.612732  0.859649  0.894585  0.105415           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2343   0.30                  0.27                  195  0.658046  0.685218  0.704615  0.617251  0.860819  0.897473  0.102527           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
6689   0.70                  0.33                  175  0.657817  0.674531  0.686154  0.631728  0.864327  0.906137  0.093863           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
4522   0.50                  0.30                  230  0.657609  0.707189  0.744615  0.588808  0.852632  0.877978  0.122022           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
5061   0.55                  0.31                  155  0.657382  0.696988  0.726154  0.600509  0.856140  0.886643  0.113357           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
5063   0.55                  0.31                  165  0.657343  0.695266  0.723077  0.602564  0.856725  0.888087  0.111913           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
5064   0.55                  0.31                  170  0.657303  0.693539  0.720000  0.604651  0.857310  0.889531  0.110469           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
2883   0.35                  0.28                  140  0.657264  0.691805  0.716923  0.606771  0.857895  0.890975  0.109025           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2884   0.35                  0.28                  145  0.657224  0.690065  0.713846  0.608924  0.858480  0.892419  0.107581           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2885   0.35                  0.28                  150  0.657183  0.688319  0.710769  0.611111  0.859064  0.893863  0.106137           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
2341   0.30                  0.27                  185  0.657143  0.686567  0.707692  0.613333  0.859649  0.895307  0.104693           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
6688   0.70                  0.33                  170  0.656848  0.674123  0.686154  0.629944  0.863743  0.905415  0.094585           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
7767   0.80                  0.34                  200  0.656848  0.674123  0.686154  0.629944  0.863743  0.905415  0.094585           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
6144   0.65                  0.32                  210  0.656797  0.710128  0.750769  0.583732  0.850877  0.874368  0.125632           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
680    0.15                  0.24                  145  0.656069  0.680864  0.698462  0.618529  0.860819  0.898917  0.101083           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
6686   0.70                  0.33                  160  0.655977  0.677303  0.692308  0.623269  0.861988  0.901805  0.098195           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6687   0.70                  0.33                  165  0.655930  0.675513  0.689231  0.625698  0.862573  0.903249  0.096751           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
5062   0.55                  0.31                  160  0.655509  0.694444  0.723077  0.599490  0.855556  0.886643  0.113357           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
7219   0.75                  0.33                  230  0.655440  0.724098  0.778462  0.565996  0.844444  0.859928  0.140072           0.229562           0.351939        0.141538  0.055385   0.055385   0.854675
2339   0.30                  0.27                  175  0.655319  0.687500  0.710769  0.607895  0.857895  0.892419  0.107581           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
2340   0.30                  0.27                  180  0.655271  0.685748  0.707692  0.610080  0.858480  0.893863  0.106137           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
677    0.15                  0.24                  130  0.655222  0.683990  0.704615  0.612299  0.859064  0.895307  0.104693           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
6684   0.70                  0.33                  150  0.655123  0.680456  0.698462  0.616848  0.860234  0.898195  0.101805           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
4520   0.50                  0.30                  210  0.655080  0.710969  0.753846  0.579196  0.849123  0.871480  0.128520           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
6685   0.70                  0.33                  155  0.655072  0.678679  0.695385  0.619178  0.860819  0.899639  0.100361           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
687    0.15                  0.24                  180  0.654815  0.669697  0.680000  0.631429  0.863743  0.906859  0.093141           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
689    0.15                  0.24                  190  0.654762  0.667881  0.676923  0.634006  0.864327  0.908303  0.091697           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
692    0.15                  0.24                  210  0.654709  0.666058  0.673846  0.636628  0.864912  0.909747  0.090253           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
2882   0.35                  0.28                  135  0.654494  0.690575  0.716923  0.602067  0.856140  0.888809  0.111191           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
1792   0.25                  0.26                  195  0.654339  0.685340  0.707692  0.608466  0.857895  0.893141  0.106859           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
679    0.15                  0.24                  140  0.654179  0.680048  0.698462  0.615176  0.859649  0.897473  0.102527           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
681    0.15                  0.24                  150  0.654124  0.678271  0.695385  0.617486  0.860234  0.898917  0.101083           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
684    0.15                  0.24                  165  0.653959  0.672903  0.686154  0.624650  0.861988  0.903249  0.096751           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
7766   0.80                  0.34                  195  0.653959  0.672903  0.686154  0.624650  0.861988  0.903249  0.096751           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
685    0.15                  0.24                  170  0.653903  0.671100  0.683077  0.627119  0.862573  0.904693  0.095307           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
8292   0.85                  0.34                  230  0.653846  0.726496  0.784615  0.560440  0.842105  0.855596  0.144404           0.218262           0.334946        0.144615  0.052308   0.052308   0.854201
5059   0.55                  0.31                  145  0.653793  0.697059  0.729231  0.592500  0.853216  0.882310  0.117690           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
691    0.15                  0.24                  200  0.653731  0.665653  0.673846  0.634783  0.864327  0.909025  0.090975           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
8841   0.90                  0.35                  210  0.653731  0.665653  0.673846  0.634783  0.864327  0.909025  0.090975           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
693    0.15                  0.24                  220  0.653614  0.661989  0.667692  0.640118  0.865497  0.911913  0.088087           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
2338   0.30                  0.27                  170  0.653465  0.686683  0.710769  0.604712  0.856725  0.890975  0.109025           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
1791   0.25                  0.26                  190  0.653409  0.684932  0.707692  0.606860  0.857310  0.892419  0.107581           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
3427   0.40                  0.29                  105  0.653409  0.684932  0.707692  0.606860  0.857310  0.892419  0.107581           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
1793   0.25                  0.26                  200  0.653352  0.683174  0.704615  0.609043  0.857895  0.893863  0.106137           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
6682   0.70                  0.33                  140  0.653352  0.683174  0.704615  0.609043  0.857895  0.893863  0.106137           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
6143   0.65                  0.32                  200  0.653333  0.710145  0.753846  0.576471  0.847953  0.870036  0.129964           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
1794   0.25                  0.26                  210  0.653295  0.681411  0.701538  0.611260  0.858480  0.895307  0.104693           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
678    0.15                  0.24                  135  0.653237  0.679641  0.698462  0.613514  0.859064  0.896751  0.103249           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
1243   0.20                  0.25                  210  0.653179  0.677864  0.695385  0.615804  0.859649  0.898195  0.101805           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
5604   0.60                  0.32                  115  0.652941  0.670695  0.683077  0.625352  0.861988  0.903971  0.096029           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
686    0.15                  0.24                  175  0.652880  0.668886  0.680000  0.627841  0.862573  0.905415  0.094585           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
5060   0.55                  0.31                  150  0.652835  0.694935  0.726154  0.592965  0.853216  0.883032  0.116968           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
688    0.15                  0.24                  185  0.652819  0.667071  0.676923  0.630372  0.863158  0.906859  0.093141           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
690    0.15                  0.24                  195  0.652757  0.665249  0.673846  0.632948  0.863743  0.908303  0.091697           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
2336   0.30                  0.27                  160  0.652661  0.689757  0.716923  0.598972  0.854971  0.887365  0.112635           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
2337   0.30                  0.27                  165  0.652542  0.686275  0.710769  0.603133  0.856140  0.890253  0.109747           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
675    0.15                  0.24                  120  0.652482  0.684524  0.707692  0.605263  0.856725  0.891697  0.108303           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
1790   0.25                  0.26                  185  0.652482  0.684524  0.707692  0.605263  0.856725  0.891697  0.108303           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
5599   0.60                  0.32                   90  0.652361  0.681004  0.701538  0.609626  0.857895  0.894585  0.105415           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
4521   0.50                  0.30                  220  0.652349  0.706395  0.747692  0.578571  0.848538  0.872202  0.127798           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
1242   0.20                  0.25                  200  0.652299  0.679234  0.698462  0.611860  0.858480  0.896029  0.103971           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
8291   0.85                  0.34                  220  0.652229  0.727273  0.787692  0.556522  0.840351  0.852708  0.147292           0.218262           0.334946        0.144615  0.052308   0.052308   0.854201
682    0.15                  0.24                  155  0.652111  0.673887  0.689231  0.618785  0.860234  0.900361  0.099639           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
7765   0.80                  0.34                  190  0.652047  0.672092  0.686154  0.621170  0.860819  0.901805  0.098195           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
8839   0.90                  0.35                  195  0.651917  0.668482  0.680000  0.626062  0.861988  0.904693  0.095307           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
2335   0.30                  0.27                  155  0.651748  0.689349  0.716923  0.597436  0.854386  0.886643  0.113357           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
4519   0.50                  0.30                  200  0.651656  0.710983  0.756923  0.572093  0.846199  0.867148  0.132852           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
694    0.15                  0.24                  230  0.651515  0.657492  0.661538  0.641791  0.865497  0.913357  0.086643           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
676    0.15                  0.24                  125  0.651494  0.682360  0.704615  0.605820  0.856725  0.892419  0.107581           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
1241   0.20                  0.25                  195  0.651363  0.678828  0.698462  0.610215  0.857895  0.895307  0.104693           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
6683   0.70                  0.33                  145  0.651363  0.678828  0.698462  0.610215  0.857895  0.895307  0.104693           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
5058   0.55                  0.31                  140  0.651099  0.695831  0.729231  0.588089  0.851462  0.880144  0.119856           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
683    0.15                  0.24                  160  0.651095  0.671687  0.686154  0.619444  0.860234  0.901083  0.098917           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
5603   0.60                  0.32                  110  0.651026  0.669885  0.683077  0.621849  0.860819  0.902527  0.097473           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
6140   0.65                  0.32                  185  0.650919  0.713874  0.763077  0.567506  0.844444  0.863538  0.136462           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
5605   0.60                  0.32                  120  0.650888  0.666263  0.676923  0.626781  0.861988  0.905415  0.094585           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
8840   0.90                  0.35                  200  0.650888  0.666263  0.676923  0.626781  0.861988  0.905415  0.094585           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
5620   0.60                  0.32                  195  0.650869  0.640547  0.633846  0.668831  0.870760  0.926354  0.073646           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
5622   0.60                  0.32                  210  0.650794  0.638629  0.630769  0.672131  0.871345  0.927798  0.072202           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
673    0.15                  0.24                  110  0.650704  0.685460  0.710769  0.600000  0.854971  0.888809  0.111191           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
674    0.15                  0.24                  115  0.650636  0.683710  0.707692  0.602094  0.855556  0.890253  0.109747           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
1789   0.25                  0.26                  180  0.650636  0.683710  0.707692  0.602094  0.855556  0.890253  0.109747           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
5601   0.60                  0.32                  100  0.650289  0.674865  0.692308  0.613079  0.858480  0.897473  0.102527           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
8838   0.90                  0.35                  190  0.650000  0.667674  0.680000  0.622535  0.860819  0.903249  0.096751           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
4518   0.50                  0.30                  195  0.650000  0.711816  0.760000  0.567816  0.844444  0.864260  0.135740           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
1233   0.20                  0.25                  155  0.649930  0.688534  0.716923  0.594388  0.853216  0.885199  0.114801           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
5606   0.60                  0.32                  125  0.649852  0.664039  0.673846  0.627507  0.861988  0.906137  0.093863           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
3426   0.40                  0.29                  100  0.649718  0.683304  0.707692  0.600522  0.854971  0.889531  0.110469           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
3976   0.45                  0.30                   95  0.649701  0.660377  0.667692  0.632653  0.863158  0.909025  0.090975           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
8842   0.90                  0.35                  220  0.649624  0.658537  0.664615  0.635294  0.863743  0.910469  0.089531           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
1238   0.20                  0.25                  180  0.649573  0.679785  0.701538  0.604775  0.856140  0.892419  0.107581           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
1239   0.20                  0.25                  185  0.649573  0.679785  0.701538  0.604775  0.856140  0.892419  0.107581           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
7218   0.75                  0.33                  220  0.649551  0.721209  0.778462  0.557269  0.840351  0.854874  0.145126           0.229562           0.351939        0.141538  0.055385   0.055385   0.854675
5600   0.60                  0.32                   95  0.649351  0.674460  0.692308  0.611413  0.857895  0.896751  0.103249           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
8844   0.90                  0.35                  240  0.649231  0.649231  0.649231  0.649231  0.866667  0.917690  0.082310           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
6141   0.65                  0.32                  190  0.649077  0.709752  0.756923  0.568129  0.844444  0.864982  0.135018           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
2334   0.30                  0.27                  150  0.649025  0.688128  0.716923  0.592875  0.852632  0.884477  0.115523           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
2881   0.35                  0.28                  130  0.649025  0.688128  0.716923  0.592875  0.852632  0.884477  0.115523           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
6142   0.65                  0.32                  195  0.649007  0.708092  0.753846  0.569767  0.845029  0.866426  0.133574           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
5619   0.60                  0.32                  190  0.648819  0.639752  0.633846  0.664516  0.869591  0.924910  0.075090           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
5607   0.60                  0.32                  130  0.648810  0.661809  0.670769  0.628242  0.861988  0.906859  0.093141           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
1235   0.20                  0.25                  165  0.648801  0.682898  0.707692  0.598958  0.854386  0.888809  0.111191           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
1788   0.25                  0.26                  175  0.648801  0.682898  0.707692  0.598958  0.854386  0.888809  0.111191           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
7217   0.75                  0.33                  210  0.648787  0.722412  0.781538  0.554585  0.839181  0.852708  0.147292           0.229562           0.351939        0.141538  0.055385   0.055385   0.854675
5621   0.60                  0.32                  200  0.648734  0.637834  0.630769  0.667752  0.870175  0.926354  0.073646           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
1237   0.20                  0.25                  175  0.648725  0.681142  0.704615  0.601050  0.854971  0.890253  0.109747           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
7761   0.80                  0.34                  170  0.648571  0.677612  0.698462  0.605333  0.856140  0.893141  0.106859           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3978   0.45                  0.30                  105  0.648485  0.654434  0.658462  0.638806  0.864327  0.912635  0.087365           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
695    0.15                  0.24                  240  0.648402  0.652574  0.655385  0.641566  0.864912  0.914079  0.085921           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
8843   0.90                  0.35                  230  0.648402  0.652574  0.655385  0.641566  0.864912  0.914079  0.085921           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
7764   0.80                  0.34                  185  0.648256  0.670475  0.686154  0.614325  0.858480  0.898917  0.101083           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
5602   0.60                  0.32                  105  0.648175  0.668675  0.683077  0.616667  0.859064  0.900361  0.099639           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
1232   0.20                  0.25                  150  0.648122  0.687721  0.716923  0.591371  0.852047  0.883755  0.116245           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
2880   0.35                  0.28                  125  0.648122  0.687721  0.716923  0.591371  0.852047  0.883755  0.116245           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
3974   0.45                  0.30                   85  0.648012  0.665054  0.676923  0.621469  0.860234  0.903249  0.096751           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
672    0.15                  0.24                  105  0.647966  0.684242  0.710769  0.595361  0.853216  0.886643  0.113357           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
1234   0.20                  0.25                  160  0.647966  0.684242  0.710769  0.595361  0.853216  0.886643  0.113357           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
1236   0.20                  0.25                  170  0.647808  0.680737  0.704615  0.599476  0.854386  0.889531  0.110469           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
1240   0.20                  0.25                  190  0.647646  0.677208  0.698462  0.603723  0.855556  0.892419  0.107581           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
5057   0.55                  0.31                  135  0.647619  0.695906  0.732308  0.580488  0.848538  0.875812  0.124188           0.260741           0.373716        0.147692  0.043077   0.043077   0.852781
3977   0.45                  0.30                  100  0.647590  0.655888  0.661538  0.634218  0.863158  0.910469  0.089531           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
7762   0.80                  0.34                  175  0.647564  0.675433  0.695385  0.605898  0.856140  0.893863  0.106137           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3997   0.45                  0.30                  200  0.647436  0.631645  0.621538  0.675585  0.871345  0.929964  0.070036           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
8290   0.85                  0.34                  210  0.647355  0.726399  0.790769  0.547974  0.836257  0.846931  0.153069           0.218262           0.334946        0.144615  0.052308   0.052308   0.854201
5623   0.60                  0.32                  220  0.647343  0.629699  0.618462  0.679054  0.871930  0.931408  0.068592           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
5611   0.60                  0.32                  150  0.647239  0.648433  0.649231  0.645260  0.865497  0.916245  0.083755           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
1231   0.20                  0.25                  145  0.647222  0.687316  0.716923  0.589873  0.851462  0.883032  0.116968           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
2333   0.30                  0.27                  145  0.647222  0.687316  0.716923  0.589873  0.851462  0.883032  0.116968           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
3973   0.45                  0.30                   80  0.647059  0.664653  0.676923  0.619718  0.859649  0.902527  0.097473           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
6681   0.70                  0.33                  135  0.646893  0.680333  0.704615  0.597911  0.853801  0.888809  0.111191           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
5617   0.60                  0.32                  180  0.646875  0.640867  0.636923  0.657143  0.867836  0.922022  0.077978           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
6139   0.65                  0.32                  180  0.646753  0.713467  0.766154  0.559551  0.840936  0.858484  0.141516           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
5608   0.60                  0.32                  135  0.646526  0.653635  0.658462  0.635015  0.863158  0.911191  0.088809           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
3979   0.45                  0.30                  110  0.646341  0.649908  0.652308  0.640483  0.864327  0.914079  0.085921           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
1785   0.25                  0.26                  160  0.646325  0.686910  0.716923  0.588384  0.850877  0.882310  0.117690           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
2879   0.35                  0.28                  120  0.646325  0.686910  0.716923  0.588384  0.850877  0.882310  0.117690           0.302855           0.358625        0.141538  0.036923   0.036923   0.851834
8837   0.90                  0.35                  185  0.646199  0.666064  0.680000  0.615599  0.858480  0.900361  0.099639           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
1786   0.25                  0.26                  165  0.646154  0.683432  0.710769  0.592308  0.852047  0.885199  0.114801           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
1787   0.25                  0.26                  170  0.646154  0.683432  0.710769  0.592308  0.852047  0.885199  0.114801           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
3998   0.45                  0.30                  210  0.646104  0.625393  0.612308  0.683849  0.872515  0.933574  0.066426           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
5609   0.60                  0.32                  140  0.645455  0.651376  0.655385  0.635821  0.863158  0.911913  0.088087           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
7763   0.80                  0.34                  180  0.645441  0.669268  0.686154  0.609290  0.856725  0.896751  0.103249           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
1230   0.20                  0.25                  140  0.645429  0.686506  0.716923  0.586902  0.850292  0.881588  0.118412           0.316027           0.367597        0.144615  0.033846   0.033846   0.851361
1784   0.25                  0.26                  155  0.645429  0.686506  0.716923  0.586902  0.850292  0.881588  0.118412           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
3981   0.45                  0.30                  120  0.645260  0.647637  0.649231  0.641337  0.864327  0.914801  0.085199           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3982   0.45                  0.30                  125  0.645161  0.645756  0.646154  0.644172  0.864912  0.916245  0.083755           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3983   0.45                  0.30                  130  0.645062  0.643869  0.643077  0.647059  0.865497  0.917690  0.082310           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
7760   0.80                  0.34                  165  0.644886  0.675998  0.698462  0.598945  0.853801  0.890253  0.109747           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3975   0.45                  0.30                   90  0.644874  0.658374  0.667692  0.623563  0.860234  0.905415  0.094585           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
5616   0.60                  0.32                  175  0.644860  0.640074  0.636923  0.652997  0.866667  0.920578  0.079422           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
5618   0.60                  0.32                  185  0.644757  0.638166  0.633846  0.656051  0.867251  0.922022  0.077978           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
2331   0.30                  0.27                  135  0.644537  0.686101  0.716923  0.585427  0.849708  0.880866  0.119134           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
2332   0.30                  0.27                  140  0.644537  0.686101  0.716923  0.585427  0.849708  0.880866  0.119134           0.314486           0.363009        0.138462  0.036923   0.036923   0.851834
6138   0.65                  0.32                  175  0.644416  0.715507  0.772308  0.552863  0.838012  0.853430  0.146570           0.247635           0.362828        0.144615  0.055385   0.055385   0.854675
8835   0.90                  0.35                  175  0.644412  0.667067  0.683077  0.609890  0.856725  0.897473  0.102527           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
5610   0.60                  0.32                  145  0.644377  0.649112  0.652308  0.636637  0.863158  0.912635  0.087365           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
671    0.15                  0.24                  100  0.644351  0.682624  0.710769  0.589286  0.850877  0.883755  0.116245           0.316015           0.364474        0.150769  0.030769   0.030769   0.850888
7757   0.80                  0.34                  150  0.644351  0.682624  0.710769  0.589286  0.850877  0.883755  0.116245           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781
3996   0.45                  0.30                  195  0.644338  0.630462  0.621538  0.668874  0.869591  0.927798  0.072202           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
8836   0.90                  0.35                  180  0.644315  0.665262  0.680000  0.612188  0.857310  0.898917  0.101083           0.205081           0.323907        0.156923  0.043077   0.043077   0.852781
3980   0.45                  0.30                  115  0.644275  0.647239  0.649231  0.639394  0.863743  0.914079  0.085921           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3425   0.40                  0.29                   95  0.644258  0.680876  0.707692  0.591260  0.851462  0.885199  0.114801           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
4517   0.50                  0.30                  190  0.644068  0.708955  0.760000  0.558824  0.840351  0.859206  0.140794           0.273925           0.377379        0.144615  0.052308   0.052308   0.854201
5598   0.60                  0.32                   85  0.644068  0.677362  0.701538  0.595300  0.852632  0.888087  0.111913           0.243588           0.363640        0.150769  0.036923   0.036923   0.851834
3984   0.45                  0.30                  135  0.643857  0.639679  0.636923  0.650943  0.866082  0.919856  0.080144           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3987   0.45                  0.30                  150  0.643750  0.637771  0.633846  0.653968  0.866667  0.921300  0.078700           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3988   0.45                  0.30                  155  0.643750  0.637771  0.633846  0.653968  0.866667  0.921300  0.078700           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
1783   0.25                  0.26                  150  0.643646  0.685697  0.716923  0.583960  0.849123  0.880144  0.119856           0.315941           0.364943        0.144615  0.036923   0.036923   0.851834
3990   0.45                  0.30                  165  0.643642  0.635856  0.630769  0.657051  0.867251  0.922744  0.077256           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3991   0.45                  0.30                  170  0.643642  0.635856  0.630769  0.657051  0.867251  0.922744  0.077256           0.261791           0.348930        0.150769  0.027692   0.027692   0.850414
3424   0.40                  0.29                   90  0.643454  0.682221  0.710769  0.587786  0.850292  0.883032  0.116968           0.279900           0.354159        0.147692  0.033846   0.033846   0.851361
6680   0.70                  0.33                  130  0.643357  0.680473  0.707692  0.589744  0.850877  0.884477  0.115523           0.223835           0.345578        0.153846  0.036923   0.036923   0.851834
7758   0.80                  0.34                  155  0.643357  0.680473  0.707692  0.589744  0.850877  0.884477  0.115523           0.216107           0.343158        0.150769  0.043077   0.043077   0.852781

Full result output for the best combination:
                 #Examples   TP   FP    TN   FN       ACC       FNR       TNR       FPR       TPR      Prec        F1        F2  AVG # affected
Component                                                                                                                                      
no_failure            1385    0  107  1278    0  0.922744       NaN  0.922744  0.077256       NaN  0.000000       NaN       NaN       43.674368
txt15_i1                 5    3    0     0    2  0.600000  0.400000       NaN       NaN  0.600000  1.000000  0.750000  0.652174      221.400000
txt15_i3                 5    0    0     0    5  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN       12.200000
txt15_conveyor           3    3    0     0    0  1.000000  0.000000       NaN       NaN  1.000000  1.000000  1.000000  1.000000      418.333333
txt15_m1               160  154    0     0    6  0.962500  0.037500       NaN       NaN  0.962500  1.000000  0.980892  0.969773      427.343750
txt15_pl                 9    5    0     0    4  0.555556  0.444444       NaN       NaN  0.555556  1.000000  0.714286  0.609756      248.222222
txt16_i3                 4    0    0     0    4  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt16_conveyor           8    2    0     0    6  0.250000  0.750000       NaN       NaN  0.250000  1.000000  0.400000  0.294118      115.250000
txt16_m3                65   55    0     0   10  0.846154  0.153846       NaN       NaN  0.846154  1.000000  0.916667  0.873016      347.815385
txt16_turntable          2    0    0     0    2  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt17_i1                16    1    0     0   15  0.062500  0.937500       NaN       NaN  0.062500  1.000000  0.117647  0.076923       23.875000
txt17_pl                14    0    0     0   14  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt18_pl                28    0    0     0   28  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN       20.642857
txt19_i4                 6    0    0     0    6  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
combined              1710  223  107  1278  102  0.877778  0.313846  0.922744  0.077256  0.686154  0.675758  0.680916  0.684049       92.404094

                 #Examples   TP   FP    TN   FN       ACC       FNR       TNR       FPR       TPR      Prec        F1        F2  AVG # affected
Component                                                                                                                                      
no_failure            1385    0  107  1278    0  0.922744       NaN  0.922744  0.077256       NaN  0.000000       NaN       NaN       43.674368
txt15_i1                 5    3    0     0    2  0.600000  0.400000       NaN       NaN  0.600000  1.000000  0.750000  0.652174      221.400000
txt15_i3                 5    0    0     0    5  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN       12.200000
txt15_conveyor           3    3    0     0    0  1.000000  0.000000       NaN       NaN  1.000000  1.000000  1.000000  1.000000      418.333333
txt15_m1               160  154    0     0    6  0.962500  0.037500       NaN       NaN  0.962500  1.000000  0.980892  0.969773      427.343750
txt15_pl                 9    5    0     0    4  0.555556  0.444444       NaN       NaN  0.555556  1.000000  0.714286  0.609756      248.222222
txt16_i3                 4    0    0     0    4  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt16_conveyor           8    2    0     0    6  0.250000  0.750000       NaN       NaN  0.250000  1.000000  0.400000  0.294118      115.250000
txt16_m3                65   55    0     0   10  0.846154  0.153846       NaN       NaN  0.846154  1.000000  0.916667  0.873016      347.815385
txt16_turntable          2    0    0     0    2  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt17_i1                16    1    0     0   15  0.062500  0.937500       NaN       NaN  0.062500  1.000000  0.117647  0.076923       23.875000
txt17_pl                14    0    0     0   14  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
txt18_pl                28    0    0     0   28  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN       20.642857
txt19_i4                 6    0    0     0    6  0.000000  1.000000       NaN       NaN  0.000000       NaN       NaN       NaN        0.000000
combined              1710  223  107  1278  102  0.877778  0.313846  0.922744  0.077256  0.686154  0.675758  0.680916  0.684049       92.404094

Execution time: 203483.85914484505
