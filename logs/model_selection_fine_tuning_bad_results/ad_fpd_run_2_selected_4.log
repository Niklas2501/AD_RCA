
Dataset loaded:
Shape of training set (example, time, channels): (20812, 500, 61)
Shape of test set (example, time, channels): (3989, 500, 61)
Shape of train validation set (example, time, channels): (2313, 500, 61)
Shape of test validation set (example, time, channels): (1710, 500, 61)
Num of classes in all: 25

Creating model based on ../configuration/hyperparameter_combinations/selected/selected_4.json hyperparameter file 

Adding feature wise convolutions with 32 filters per feature, 3 kernels and 1 strides ...
Adding feature wise convolutions with 1 filters per feature, 3 kernels and 1 strides ...
Adding feature based graph attention layer ...
Adding time based graph attention layer ...
Adding GRU layer with 256 units ...
Adding GRU layer with 61 units ...
Adding GRU layer to forecasting model with 256 units ...
Adding VAE as reconstruction model with dimensions 3072 & 1536 and ...
The RBM reconstructs the output of the gru layer.

Epoch 0
	Step 0: mean loss = 1.3122
	Step 50: mean loss = 0.5048
	Step 100: mean loss = 0.3331
	Step 150: mean loss = 0.2644

	Loss on validation set after epoch 0: 0.1157

Epoch 1
	Step 0: mean loss = 0.1113
	Step 50: mean loss = 0.1102
	Step 100: mean loss = 0.1065
	Step 150: mean loss = 0.1031

	Loss on validation set after epoch 1: 0.0938

Epoch 2
	Step 0: mean loss = 0.0922
	Step 50: mean loss = 0.0902
	Step 100: mean loss = 0.0883
	Step 150: mean loss = 0.0863

	Loss on validation set after epoch 2: 0.0810

Epoch 3
	Step 0: mean loss = 0.0820
	Step 50: mean loss = 0.0779
	Step 100: mean loss = 0.0766
	Step 150: mean loss = 0.0756

	Loss on validation set after epoch 3: 0.0720

Epoch 4
	Step 0: mean loss = 0.0748
	Step 50: mean loss = 0.0701
	Step 100: mean loss = 0.0690
	Step 150: mean loss = 0.0677

	Loss on validation set after epoch 4: 0.0641

Epoch 5
	Step 0: mean loss = 0.0645
	Step 50: mean loss = 0.0633
	Step 100: mean loss = 0.0630
	Step 150: mean loss = 0.0624

	Loss on validation set after epoch 5: 0.0594

Epoch 6
	Step 0: mean loss = 0.0651
	Step 50: mean loss = 0.0598
	Step 100: mean loss = 0.0595
	Step 150: mean loss = 0.0592

	Loss on validation set after epoch 6: 0.0578

Epoch 7
	Step 0: mean loss = 0.0592
	Step 50: mean loss = 0.0569
	Step 100: mean loss = 0.0562
	Step 150: mean loss = 0.0554

	Loss on validation set after epoch 7: 0.0525

Epoch 8
	Step 0: mean loss = 0.0512
	Step 50: mean loss = 0.0514
	Step 100: mean loss = 0.0510
	Step 150: mean loss = 0.0505

	Loss on validation set after epoch 8: 0.0485

Epoch 9
	Step 0: mean loss = 0.0501
	Step 50: mean loss = 0.0482
	Step 100: mean loss = 0.0478
	Step 150: mean loss = 0.0475

	Loss on validation set after epoch 9: 0.0467

Epoch 10
	Step 0: mean loss = 0.0431
	Step 50: mean loss = 0.0454
	Step 100: mean loss = 0.0454
	Step 150: mean loss = 0.0454

	Loss on validation set after epoch 10: 0.0440

Epoch 11
	Step 0: mean loss = 0.0428
	Step 50: mean loss = 0.0438
	Step 100: mean loss = 0.0438
	Step 150: mean loss = 0.0438

	Loss on validation set after epoch 11: 0.0439

Epoch 12
	Step 0: mean loss = 0.0415
	Step 50: mean loss = 0.0423
	Step 100: mean loss = 0.0423
	Step 150: mean loss = 0.0423

	Loss on validation set after epoch 12: 0.0416

Epoch 13
	Step 0: mean loss = 0.0430
	Step 50: mean loss = 0.0414
	Step 100: mean loss = 0.0413
	Step 150: mean loss = 0.0489

	Loss on validation set after epoch 13: 0.0500

Epoch 14
	Step 0: mean loss = 0.0539
	Step 50: mean loss = 0.0468
	Step 100: mean loss = 0.0458
	Step 150: mean loss = 0.0456

	Loss on validation set after epoch 14: 0.0428

Epoch 15
	Step 0: mean loss = 0.0392
	Step 50: mean loss = 0.0426
	Step 100: mean loss = 0.0423
	Step 150: mean loss = 0.0421

	Loss on validation set after epoch 15: 0.0423

Epoch 16
	Step 0: mean loss = 0.0380
	Step 50: mean loss = 0.0408
	Step 100: mean loss = 0.0409
	Step 150: mean loss = 0.0410

	Loss on validation set after epoch 16: 0.0408

Epoch 17
	Step 0: mean loss = 0.0420
	Step 50: mean loss = 0.0401
	Step 100: mean loss = 0.0402
	Step 150: mean loss = 0.0401

	Loss on validation set after epoch 17: 0.0394

Epoch 18
	Step 0: mean loss = 0.0363
	Step 50: mean loss = 0.0392
	Step 100: mean loss = 0.0394
	Step 150: mean loss = 0.0394

	Loss on validation set after epoch 18: 0.0389

Epoch 19
	Step 0: mean loss = 0.0415
	Step 50: mean loss = 0.0385
	Step 100: mean loss = 0.0388
	Step 150: mean loss = 0.0387

	Loss on validation set after epoch 19: 0.0378

Epoch 20
	Step 0: mean loss = 0.0378
	Step 50: mean loss = 0.0382
	Step 100: mean loss = 0.0381
	Step 150: mean loss = 0.0381

	Loss on validation set after epoch 20: 0.0370

Epoch 21
	Step 0: mean loss = 0.0393
	Step 50: mean loss = 0.0381
	Step 100: mean loss = 0.0378
	Step 150: mean loss = 0.0378

	Loss on validation set after epoch 21: 0.0373

Epoch 22
	Step 0: mean loss = 0.0385
	Step 50: mean loss = 0.0372
	Step 100: mean loss = 0.0373
	Step 150: mean loss = 0.0373

	Loss on validation set after epoch 22: 0.0373

Epoch 23
	Step 0: mean loss = 0.0355
	Step 50: mean loss = 0.0366
	Step 100: mean loss = 0.0367
	Step 150: mean loss = 0.0367

	Loss on validation set after epoch 23: 0.0361

Epoch 24
	Step 0: mean loss = 0.0354
	Step 50: mean loss = 0.0366
	Step 100: mean loss = 0.0364
	Step 150: mean loss = 0.0363

	Loss on validation set after epoch 24: 0.0358

Epoch 25
	Step 0: mean loss = 0.0335
	Step 50: mean loss = 0.0359
	Step 100: mean loss = 0.0358
	Step 150: mean loss = 0.0357

	Loss on validation set after epoch 25: 0.0344

Epoch 26
	Step 0: mean loss = 0.0347
	Step 50: mean loss = 0.0348
	Step 100: mean loss = 0.0349
	Step 150: mean loss = 0.0349

	Loss on validation set after epoch 26: 0.0341

Epoch 27
	Step 0: mean loss = 0.0353
	Step 50: mean loss = 0.0342
	Step 100: mean loss = 0.0341
	Step 150: mean loss = 0.0341

	Loss on validation set after epoch 27: 0.0334

Epoch 28
	Step 0: mean loss = 0.0346
	Step 50: mean loss = 0.0334
	Step 100: mean loss = 0.0336
	Step 150: mean loss = 0.0336

	Loss on validation set after epoch 28: 0.0330

Epoch 29
	Step 0: mean loss = 0.0359
	Step 50: mean loss = 0.0331
	Step 100: mean loss = 0.0333
	Step 150: mean loss = 0.0332

	Loss on validation set after epoch 29: 0.0334

Epoch 30
	Step 0: mean loss = 0.0343
	Step 50: mean loss = 0.0326
	Step 100: mean loss = 0.0327
	Step 150: mean loss = 0.0327

	Loss on validation set after epoch 30: 0.0317

Epoch 31
	Step 0: mean loss = 0.0323
	Step 50: mean loss = 0.0318
	Step 100: mean loss = 0.0319
	Step 150: mean loss = 0.0321

	Loss on validation set after epoch 31: 0.0310

Epoch 32
	Step 0: mean loss = 0.0296
	Step 50: mean loss = 0.0311
	Step 100: mean loss = 0.0314
	Step 150: mean loss = 0.0314

	Loss on validation set after epoch 32: 0.0302

Epoch 33
	Step 0: mean loss = 0.0316
	Step 50: mean loss = 0.0307
	Step 100: mean loss = 0.0308
	Step 150: mean loss = 0.0309

	Loss on validation set after epoch 33: 0.0310

Epoch 34
	Step 0: mean loss = 0.0333
	Step 50: mean loss = 0.0303
	Step 100: mean loss = 0.0306
	Step 150: mean loss = 0.0305

	Loss on validation set after epoch 34: 0.0310

Epoch 35
	Step 0: mean loss = 0.0310
	Step 50: mean loss = 0.0297
	Step 100: mean loss = 0.0300
	Step 150: mean loss = 0.0301

	Loss on validation set after epoch 35: 0.0296

Epoch 36
	Step 0: mean loss = 0.0303
	Step 50: mean loss = 0.0302
	Step 100: mean loss = 0.0299
	Step 150: mean loss = 0.0300

	Loss on validation set after epoch 36: 0.0296

Epoch 37
	Step 0: mean loss = 0.0293
	Step 50: mean loss = 0.0294
	Step 100: mean loss = 0.0293
	Step 150: mean loss = 0.0293

	Loss on validation set after epoch 37: 0.0289

Epoch 38
	Step 0: mean loss = 0.0314
	Step 50: mean loss = 0.0287
	Step 100: mean loss = 0.0290
	Step 150: mean loss = 0.0290

	Loss on validation set after epoch 38: 0.0292

Epoch 39
	Step 0: mean loss = 0.0271
	Step 50: mean loss = 0.0286
	Step 100: mean loss = 0.0288
	Step 150: mean loss = 0.0288

	Loss on validation set after epoch 39: 0.0282

Epoch 40
	Step 0: mean loss = 0.0310
	Step 50: mean loss = 0.0287
	Step 100: mean loss = 0.0286
	Step 150: mean loss = 0.0285

	Loss on validation set after epoch 40: 0.0285

Epoch 41
	Step 0: mean loss = 0.0289
	Step 50: mean loss = 0.0280
	Step 100: mean loss = 0.0280
	Step 150: mean loss = 0.0281

	Loss on validation set after epoch 41: 0.0278

Epoch 42
	Step 0: mean loss = 0.0247
	Step 50: mean loss = 0.0274
	Step 100: mean loss = 0.0277
	Step 150: mean loss = 0.0277

	Loss on validation set after epoch 42: 0.0301

Epoch 43
	Step 0: mean loss = 0.0269
	Step 50: mean loss = 0.0279
	Step 100: mean loss = 0.0278
	Step 150: mean loss = 0.0277

	Loss on validation set after epoch 43: 0.0274

Epoch 44
	Step 0: mean loss = 0.0287
	Step 50: mean loss = 0.0268
	Step 100: mean loss = 0.0272
	Step 150: mean loss = 0.0273

	Loss on validation set after epoch 44: 0.0273

Epoch 45
	Step 0: mean loss = 0.0261
	Step 50: mean loss = 0.0270
	Step 100: mean loss = 0.0271
	Step 150: mean loss = 0.0270

	Loss on validation set after epoch 45: 0.0259

Epoch 46
	Step 0: mean loss = 0.0292
	Step 50: mean loss = 0.0269
	Step 100: mean loss = 0.0270
	Step 150: mean loss = 0.0268

	Loss on validation set after epoch 46: 0.0254

Epoch 47
	Step 0: mean loss = 0.0251
	Step 50: mean loss = 0.0265
	Step 100: mean loss = 0.0266
	Step 150: mean loss = 0.0264

	Loss on validation set after epoch 47: 0.0279

Epoch 48
	Step 0: mean loss = 0.0289
	Step 50: mean loss = 0.0268
	Step 100: mean loss = 0.0266
	Step 150: mean loss = 0.0264

	Loss on validation set after epoch 48: 0.0254

Epoch 49
	Step 0: mean loss = 0.0264
	Step 50: mean loss = 0.0263
	Step 100: mean loss = 0.0261
	Step 150: mean loss = 0.0260

	Loss on validation set after epoch 49: 0.0261

Epoch 50
	Step 0: mean loss = 0.0297
	Step 50: mean loss = 0.0256
	Step 100: mean loss = 0.0263
	Step 150: mean loss = 0.0262

	Loss on validation set after epoch 50: 0.0273

Epoch 51
	Step 0: mean loss = 0.0273
	Step 50: mean loss = 0.0255
	Step 100: mean loss = 0.0256
	Step 150: mean loss = 0.0256

	Loss on validation set after epoch 51: 0.0253

Epoch 52
	Step 0: mean loss = 0.0267
	Step 50: mean loss = 0.0252
	Step 100: mean loss = 0.0254
	Step 150: mean loss = 0.0254

	Loss on validation set after epoch 52: 0.0258

Epoch 53
	Step 0: mean loss = 0.0254
	Step 50: mean loss = 0.0253
	Step 100: mean loss = 0.0252
	Step 150: mean loss = 0.0252

	Loss on validation set after epoch 53: 0.0251

Epoch 54
	Step 0: mean loss = 0.0275
	Step 50: mean loss = 0.0253
	Step 100: mean loss = 0.0253
	Step 150: mean loss = 0.0254

	Loss on validation set after epoch 54: 0.0245

Epoch 55
	Step 0: mean loss = 0.0269
	Step 50: mean loss = 0.0259
	Step 100: mean loss = 0.0319
	Step 150: mean loss = 0.0305

	Loss on validation set after epoch 55: 0.0271

Epoch 56
	Step 0: mean loss = 0.0264
	Step 50: mean loss = 0.0272
	Step 100: mean loss = 0.0273
	Step 150: mean loss = 0.0272

	Loss on validation set after epoch 56: 0.0267

Epoch 57
	Step 0: mean loss = 0.0279
	Step 50: mean loss = 0.0269
	Step 100: mean loss = 0.0269
	Step 150: mean loss = 0.0267

	Loss on validation set after epoch 57: 0.0256

Epoch 58
	Step 0: mean loss = 0.0305
	Step 50: mean loss = 0.0259
	Step 100: mean loss = 0.0261
	Step 150: mean loss = 0.0260

	Loss on validation set after epoch 58: 0.0263

Epoch 59
	Step 0: mean loss = 0.0298
	Step 50: mean loss = 0.0261
	Step 100: mean loss = 0.0257
	Step 150: mean loss = 0.0255

	Loss on validation set after epoch 59: 0.0243

Epoch 60
	Step 0: mean loss = 0.0248
	Step 50: mean loss = 0.0247
	Step 100: mean loss = 0.0248
	Step 150: mean loss = 0.0246

	Loss on validation set after epoch 60: 0.0238

Epoch 61
	Step 0: mean loss = 0.0268
	Step 50: mean loss = 0.0237
	Step 100: mean loss = 0.0240
	Step 150: mean loss = 0.0239

	Loss on validation set after epoch 61: 0.0244

Epoch 62
	Step 0: mean loss = 0.0267
	Step 50: mean loss = 0.0239
	Step 100: mean loss = 0.0237
	Step 150: mean loss = 0.0236

	Loss on validation set after epoch 62: 0.0233

Epoch 63
	Step 0: mean loss = 0.0222
	Step 50: mean loss = 0.0231
	Step 100: mean loss = 0.0235
	Step 150: mean loss = 0.0235

	Loss on validation set after epoch 63: 0.0244

Epoch 64
	Step 0: mean loss = 0.0257
	Step 50: mean loss = 0.0235
	Step 100: mean loss = 0.0232
	Step 150: mean loss = 0.0232

	Loss on validation set after epoch 64: 0.0233

Epoch 65
	Step 0: mean loss = 0.0236
	Step 50: mean loss = 0.0227
	Step 100: mean loss = 0.0228
	Step 150: mean loss = 0.0228

	Loss on validation set after epoch 65: 0.0220

Epoch 66
	Step 0: mean loss = 0.0210
	Step 50: mean loss = 0.0228
	Step 100: mean loss = 0.0227
	Step 150: mean loss = 0.0227

	Loss on validation set after epoch 66: 0.0221

Epoch 67
	Step 0: mean loss = 0.0211
	Step 50: mean loss = 0.0226
	Step 100: mean loss = 0.0227
	Step 150: mean loss = 0.0226

	Loss on validation set after epoch 67: 0.0219

Epoch 68
	Step 0: mean loss = 0.0216
	Step 50: mean loss = 0.0221
	Step 100: mean loss = 0.0223
	Step 150: mean loss = 0.0223

	Loss on validation set after epoch 68: 0.0219

Epoch 69
	Step 0: mean loss = 0.0239
	Step 50: mean loss = 0.0223
	Step 100: mean loss = 0.0223
	Step 150: mean loss = 0.0223

	Loss on validation set after epoch 69: 0.0214

Epoch 70
	Step 0: mean loss = 0.0257
	Step 50: mean loss = 0.0216
	Step 100: mean loss = 0.0219
	Step 150: mean loss = 0.0218

	Loss on validation set after epoch 70: 0.0208

Epoch 71
	Step 0: mean loss = 0.0237
	Step 50: mean loss = 0.0213
	Step 100: mean loss = 0.0215
	Step 150: mean loss = 0.0218

	Loss on validation set after epoch 71: 0.0223

Epoch 72
	Step 0: mean loss = 0.0241
	Step 50: mean loss = 0.0215
	Step 100: mean loss = 0.0216
	Step 150: mean loss = 0.0216

	Loss on validation set after epoch 72: 0.0210

Epoch 73
	Step 0: mean loss = 0.0254
	Step 50: mean loss = 0.0212
	Step 100: mean loss = 0.0212
	Step 150: mean loss = 0.0212

	Loss on validation set after epoch 73: 0.0205

Epoch 74
	Step 0: mean loss = 0.0211
	Step 50: mean loss = 0.0208
	Step 100: mean loss = 0.0211
	Step 150: mean loss = 0.0209

	Loss on validation set after epoch 74: 0.0205

Epoch 75
	Step 0: mean loss = 0.0216
	Step 50: mean loss = 0.0206
	Step 100: mean loss = 0.0209
	Step 150: mean loss = 0.0208

	Loss on validation set after epoch 75: 0.0194

Epoch 76
	Step 0: mean loss = 0.0202
	Step 50: mean loss = 0.0205
	Step 100: mean loss = 0.0206
	Step 150: mean loss = 0.0208

	Loss on validation set after epoch 76: 0.0204

Epoch 77
	Step 0: mean loss = 0.0182
	Step 50: mean loss = 0.0207
	Step 100: mean loss = 0.0205
	Step 150: mean loss = 0.0204

	Loss on validation set after epoch 77: 0.0199

Epoch 78
	Step 0: mean loss = 0.0201
	Step 50: mean loss = 0.0203
	Step 100: mean loss = 0.0203
	Step 150: mean loss = 0.0202

	Loss on validation set after epoch 78: 0.0203

Epoch 79
	Step 0: mean loss = 0.0205
	Step 50: mean loss = 0.0200
	Step 100: mean loss = 0.0202
	Step 150: mean loss = 0.0200

	Loss on validation set after epoch 79: 0.0194

Epoch 80
	Step 0: mean loss = 0.0212
	Step 50: mean loss = 0.0200
	Step 100: mean loss = 0.0199
	Step 150: mean loss = 0.0199

	Loss on validation set after epoch 80: 0.0200

Epoch 81
	Step 0: mean loss = 0.0201
	Step 50: mean loss = 0.0196
	Step 100: mean loss = 0.0199
	Step 150: mean loss = 0.0198

	Loss on validation set after epoch 81: 0.0190

Epoch 82
	Step 0: mean loss = 0.0175
	Step 50: mean loss = 0.0203
	Step 100: mean loss = 0.0199
	Step 150: mean loss = 0.0197

	Loss on validation set after epoch 82: 0.0193

Epoch 83
	Step 0: mean loss = 0.0196
	Step 50: mean loss = 0.0191
	Step 100: mean loss = 0.0192
	Step 150: mean loss = 0.0192

	Loss on validation set after epoch 83: 0.0189

Epoch 84
	Step 0: mean loss = 0.0196
	Step 50: mean loss = 0.0192
	Step 100: mean loss = 0.0190
	Step 150: mean loss = 0.0191

	Loss on validation set after epoch 84: 0.0187

Epoch 85
	Step 0: mean loss = 0.0211
	Step 50: mean loss = 0.0189
	Step 100: mean loss = 0.0188
	Step 150: mean loss = 0.0188

	Loss on validation set after epoch 85: 0.0198

Epoch 86
	Step 0: mean loss = 0.0231
	Step 50: mean loss = 0.0187
	Step 100: mean loss = 0.0189
	Step 150: mean loss = 0.0189

	Loss on validation set after epoch 86: 0.0181

Epoch 87
	Step 0: mean loss = 0.0157
	Step 50: mean loss = 0.0183
	Step 100: mean loss = 0.0186
	Step 150: mean loss = 0.0185

	Loss on validation set after epoch 87: 0.0182

Epoch 88
	Step 0: mean loss = 0.0166
	Step 50: mean loss = 0.0184
	Step 100: mean loss = 0.0184
	Step 150: mean loss = 0.0184

	Loss on validation set after epoch 88: 0.0178

Epoch 89
	Step 0: mean loss = 0.0183
	Step 50: mean loss = 0.0181
	Step 100: mean loss = 0.0182
	Step 150: mean loss = 0.0183

	Loss on validation set after epoch 89: 0.0177

Epoch 90
	Step 0: mean loss = 0.0195
	Step 50: mean loss = 0.0178
	Step 100: mean loss = 0.0179
	Step 150: mean loss = 0.0179

	Loss on validation set after epoch 90: 0.0179

Epoch 91
	Step 0: mean loss = 0.0177
	Step 50: mean loss = 0.0176
	Step 100: mean loss = 0.0178
	Step 150: mean loss = 0.0177

	Loss on validation set after epoch 91: 0.0189

Epoch 92
	Step 0: mean loss = 0.0188
	Step 50: mean loss = 0.0189
	Step 100: mean loss = 0.0183
	Step 150: mean loss = 0.0181

	Loss on validation set after epoch 92: 0.0178

Epoch 93
	Step 0: mean loss = 0.0181
	Step 50: mean loss = 0.0176
	Step 100: mean loss = 0.0174
	Step 150: mean loss = 0.0174

	Loss on validation set after epoch 93: 0.0209

Epoch 94
	Step 0: mean loss = 0.0261
	Step 50: mean loss = 0.0179
	Step 100: mean loss = 0.0175
	Step 150: mean loss = 0.0175

	Loss on validation set after epoch 94: 0.0166

Epoch 95
	Step 0: mean loss = 0.0161
	Step 50: mean loss = 0.0178
	Step 100: mean loss = 0.0176
	Step 150: mean loss = 0.0175

	Loss on validation set after epoch 95: 0.0192

Epoch 96
	Step 0: mean loss = 0.0184
	Step 50: mean loss = 0.0176
	Step 100: mean loss = 0.0174
	Step 150: mean loss = 0.0173

	Loss on validation set after epoch 96: 0.0163

Epoch 97
	Step 0: mean loss = 0.0210
	Step 50: mean loss = 0.0176
	Step 100: mean loss = 0.0173
	Step 150: mean loss = 0.0172

	Loss on validation set after epoch 97: 0.0168

Epoch 98
	Step 0: mean loss = 0.0202
	Step 50: mean loss = 0.0172
	Step 100: mean loss = 0.0170
	Step 150: mean loss = 0.0170

	Loss on validation set after epoch 98: 0.0163

Epoch 99
	Step 0: mean loss = 0.0156
	Step 50: mean loss = 0.0170
	Step 100: mean loss = 0.0168
	Step 150: mean loss = 0.0167

	Loss on validation set after epoch 99: 0.0163

Epoch 100
	Step 0: mean loss = 0.0170
	Step 50: mean loss = 0.0166
	Step 100: mean loss = 0.0167
	Step 150: mean loss = 0.0167

	Loss on validation set after epoch 100: 0.0168

Epoch 101
	Step 0: mean loss = 0.0174
	Step 50: mean loss = 0.0168
	Step 100: mean loss = 0.0168
	Step 150: mean loss = 0.0167

	Loss on validation set after epoch 101: 0.0172

Epoch 102
	Step 0: mean loss = 0.0154
	Step 50: mean loss = 0.0166
	Step 100: mean loss = 0.0166
	Step 150: mean loss = 0.0165

	Loss on validation set after epoch 102: 0.0163

Epoch 103
	Step 0: mean loss = 0.0146
	Step 50: mean loss = 0.0162
	Step 100: mean loss = 0.0163
	Step 150: mean loss = 0.0165

	Loss on validation set after epoch 103: 0.0161

Epoch 104
	Step 0: mean loss = 0.0173
	Step 50: mean loss = 0.0163
	Step 100: mean loss = 0.0163
	Step 150: mean loss = 0.0163

	Loss on validation set after epoch 104: 0.0160

Epoch 105
	Step 0: mean loss = 0.0165
	Step 50: mean loss = 0.0163
	Step 100: mean loss = 0.0163
	Step 150: mean loss = 0.0166

	Loss on validation set after epoch 105: 0.0164

Epoch 106
	Step 0: mean loss = 0.0167
	Step 50: mean loss = 0.0162
	Step 100: mean loss = 0.0161
	Step 150: mean loss = 0.0161

	Loss on validation set after epoch 106: 0.0159

Epoch 107
	Step 0: mean loss = 0.0174
	Step 50: mean loss = 0.0161
	Step 100: mean loss = 0.0160
	Step 150: mean loss = 0.0160

	Loss on validation set after epoch 107: 0.0159

Epoch 108
	Step 0: mean loss = 0.0174
	Step 50: mean loss = 0.0159
	Step 100: mean loss = 0.0158
	Step 150: mean loss = 0.0157

	Loss on validation set after epoch 108: 0.0155

Epoch 109
	Step 0: mean loss = 0.0157
	Step 50: mean loss = 0.0157
	Step 100: mean loss = 0.0157
	Step 150: mean loss = 0.0160

	Loss on validation set after epoch 109: 0.0155

Epoch 110
	Step 0: mean loss = 0.0142
	Step 50: mean loss = 0.0156
	Step 100: mean loss = 0.0157
	Step 150: mean loss = 0.0158

	Loss on validation set after epoch 110: 0.0154

Epoch 111
	Step 0: mean loss = 0.0134
	Step 50: mean loss = 0.0157
	Step 100: mean loss = 0.0155
	Step 150: mean loss = 0.0156

	Loss on validation set after epoch 111: 0.0173

Epoch 112
	Step 0: mean loss = 0.0178
	Step 50: mean loss = 0.0163
	Step 100: mean loss = 0.0162
	Step 150: mean loss = 0.0160

	Loss on validation set after epoch 112: 0.0157

Epoch 113
	Step 0: mean loss = 0.0176
	Step 50: mean loss = 0.0153
	Step 100: mean loss = 0.0153
	Step 150: mean loss = 0.0154

	Loss on validation set after epoch 113: 0.0168

Epoch 114
	Step 0: mean loss = 0.0153
	Step 50: mean loss = 0.0154
	Step 100: mean loss = 0.0154
	Step 150: mean loss = 0.0154

	Loss on validation set after epoch 114: 0.0149

Epoch 115
	Step 0: mean loss = 0.0131
	Step 50: mean loss = 0.0154
	Step 100: mean loss = 0.0155
	Step 150: mean loss = 0.0155

	Loss on validation set after epoch 115: 0.0158

Epoch 116
	Step 0: mean loss = 0.0178
	Step 50: mean loss = 0.0153
	Step 100: mean loss = 0.0152
	Step 150: mean loss = 0.0154

	Loss on validation set after epoch 116: 0.0152

Epoch 117
	Step 0: mean loss = 0.0179
	Step 50: mean loss = 0.0151
	Step 100: mean loss = 0.0150
	Step 150: mean loss = 0.0150

	Loss on validation set after epoch 117: 0.0154

Epoch 118
	Step 0: mean loss = 0.0148
	Step 50: mean loss = 0.0150
	Step 100: mean loss = 0.0151
	Step 150: mean loss = 0.0150

	Loss on validation set after epoch 118: 0.0144

Epoch 119
	Step 0: mean loss = 0.0154
	Step 50: mean loss = 0.0147
	Step 100: mean loss = 0.0148
	Step 150: mean loss = 0.0147

	Loss on validation set after epoch 119: 0.0148

Epoch 120
	Step 0: mean loss = 0.0166
	Step 50: mean loss = 0.0147
	Step 100: mean loss = 0.0146
	Step 150: mean loss = 0.0147

	Loss on validation set after epoch 120: 0.0147

Epoch 121
	Step 0: mean loss = 0.0164
	Step 50: mean loss = 0.0160
	Step 100: mean loss = 0.0153
	Step 150: mean loss = 0.0150

	Loss on validation set after epoch 121: 0.0152

Epoch 122
	Step 0: mean loss = 0.0155
	Step 50: mean loss = 0.0145
	Step 100: mean loss = 0.0144
	Step 150: mean loss = 0.0146

	Loss on validation set after epoch 122: 0.0145

Epoch 123
	Step 0: mean loss = 0.0172
	Step 50: mean loss = 0.0144
	Step 100: mean loss = 0.0145
	Step 150: mean loss = 0.0147

	Loss on validation set after epoch 123: 0.0151

Epoch 124
	Step 0: mean loss = 0.0139
	Step 50: mean loss = 0.0146
	Step 100: mean loss = 0.0145
	Step 150: mean loss = 0.0145

	Loss on validation set after epoch 124: 0.0142

Epoch 125
	Step 0: mean loss = 0.0170
	Step 50: mean loss = 0.0144
	Step 100: mean loss = 0.0143
	Step 150: mean loss = 0.0143

	Loss on validation set after epoch 125: 0.0144

Epoch 126
	Step 0: mean loss = 0.0142
	Step 50: mean loss = 0.0142
	Step 100: mean loss = 0.0143
	Step 150: mean loss = 0.0143

	Loss on validation set after epoch 126: 0.0145

Epoch 127
	Step 0: mean loss = 0.0162
	Step 50: mean loss = 0.0143
	Step 100: mean loss = 0.0143
	Step 150: mean loss = 0.0142

	Loss on validation set after epoch 127: 0.0138

Epoch 128
	Step 0: mean loss = 0.0140
	Step 50: mean loss = 0.0145
	Step 100: mean loss = 0.0144
	Step 150: mean loss = 0.0143

	Loss on validation set after epoch 128: 0.0139

Epoch 129
	Step 0: mean loss = 0.0179
	Step 50: mean loss = 0.0139
	Step 100: mean loss = 0.0140
	Step 150: mean loss = 0.0140

	Loss on validation set after epoch 129: 0.0141

Epoch 130
	Step 0: mean loss = 0.0155
	Step 50: mean loss = 0.0155
	Step 100: mean loss = 0.0148
	Step 150: mean loss = 0.0145

	Loss on validation set after epoch 130: 0.0141

Epoch 131
	Step 0: mean loss = 0.0141
	Step 50: mean loss = 0.0138
	Step 100: mean loss = 0.0138
	Step 150: mean loss = 0.0140

	Loss on validation set after epoch 131: 0.0143

Epoch 132
	Step 0: mean loss = 0.0134
	Step 50: mean loss = 0.0137
	Step 100: mean loss = 0.0138
	Step 150: mean loss = 0.0138

	Loss on validation set after epoch 132: 0.0136

Epoch 133
	Step 0: mean loss = 0.0137
	Step 50: mean loss = 0.0136
	Step 100: mean loss = 0.0136
	Step 150: mean loss = 0.0137

	Loss on validation set after epoch 133: 0.0143

Epoch 134
	Step 0: mean loss = 0.0135
	Step 50: mean loss = 0.0136
	Step 100: mean loss = 0.0136
	Step 150: mean loss = 0.0136

	Loss on validation set after epoch 134: 0.0132

Epoch 135
	Step 0: mean loss = 0.0121
	Step 50: mean loss = 0.0134
	Step 100: mean loss = 0.0138
	Step 150: mean loss = 0.0137

	Loss on validation set after epoch 135: 0.0137

Epoch 136
	Step 0: mean loss = 0.0144
	Step 50: mean loss = 0.0137
	Step 100: mean loss = 0.0135
	Step 150: mean loss = 0.0135

	Loss on validation set after epoch 136: 0.0134

Epoch 137
	Step 0: mean loss = 0.0116
	Step 50: mean loss = 0.0136
	Step 100: mean loss = 0.0135
	Step 150: mean loss = 0.0135

	Loss on validation set after epoch 137: 0.0147

Epoch 138
	Step 0: mean loss = 0.0117
	Step 50: mean loss = 0.0133
	Step 100: mean loss = 0.0132
	Step 150: mean loss = 0.0132

	Loss on validation set after epoch 138: 0.0136

Epoch 139
	Step 0: mean loss = 0.0150
	Step 50: mean loss = 0.0130
	Step 100: mean loss = 0.0131
	Step 150: mean loss = 0.0131

	Loss on validation set after epoch 139: 0.0138

Epoch 140
	Step 0: mean loss = 0.0145
	Step 50: mean loss = 0.0132
	Step 100: mean loss = 0.0131
	Step 150: mean loss = 0.0131

	Loss on validation set after epoch 140: 0.0131

Epoch 141
	Step 0: mean loss = 0.0146
	Step 50: mean loss = 0.0131
	Step 100: mean loss = 0.0129
	Step 150: mean loss = 0.0129

	Loss on validation set after epoch 141: 0.0131

Epoch 142
	Step 0: mean loss = 0.0135
	Step 50: mean loss = 0.0129
	Step 100: mean loss = 0.0128
	Step 150: mean loss = 0.0128

	Loss on validation set after epoch 142: 0.0135

Epoch 143
	Step 0: mean loss = 0.0116
	Step 50: mean loss = 0.0130
	Step 100: mean loss = 0.0129
	Step 150: mean loss = 0.0128

	Loss on validation set after epoch 143: 0.0129

Epoch 144
	Step 0: mean loss = 0.0109
	Step 50: mean loss = 0.0126
	Step 100: mean loss = 0.0127
	Step 150: mean loss = 0.0127

	Loss on validation set after epoch 144: 0.0134

Epoch 145
	Step 0: mean loss = 0.0145
	Step 50: mean loss = 0.0123
	Step 100: mean loss = 0.0126
	Step 150: mean loss = 0.0126

	Loss on validation set after epoch 145: 0.0123

Epoch 146
	Step 0: mean loss = 0.0119
	Step 50: mean loss = 0.0123
	Step 100: mean loss = 0.0124
	Step 150: mean loss = 0.0124

	Loss on validation set after epoch 146: 0.0126

Epoch 147
	Step 0: mean loss = 0.0126
	Step 50: mean loss = 0.0127
	Step 100: mean loss = 0.0127
	Step 150: mean loss = 0.0128

	Loss on validation set after epoch 147: 0.0127

Epoch 148
	Step 0: mean loss = 0.0122
	Step 50: mean loss = 0.0125
	Step 100: mean loss = 0.0124
	Step 150: mean loss = 0.0124

	Loss on validation set after epoch 148: 0.0132

Epoch 149
	Step 0: mean loss = 0.0130
	Step 50: mean loss = 0.0122
	Step 100: mean loss = 0.0123
	Step 150: mean loss = 0.0123

	Loss on validation set after epoch 149: 0.0135

Epoch 150
	Step 0: mean loss = 0.0122
	Step 50: mean loss = 0.0129
	Step 100: mean loss = 0.0126
	Step 150: mean loss = 0.0125

	Loss on validation set after epoch 150: 0.0124

Epoch 151
	Step 0: mean loss = 0.0129
	Step 50: mean loss = 0.0122
	Step 100: mean loss = 0.0291
	Step 150: mean loss = 0.0395

	Loss on validation set after epoch 151: 0.0493

Epoch 152
	Step 0: mean loss = 0.0462
	Step 50: mean loss = 0.0457
	Step 100: mean loss = 0.0427
	Step 150: mean loss = 0.0411

	Loss on validation set after epoch 152: 0.0360

Epoch 153
	Step 0: mean loss = 0.0344
	Step 50: mean loss = 0.0348
	Step 100: mean loss = 0.0336
	Step 150: mean loss = 0.0327

	Loss on validation set after epoch 153: 0.0308

Epoch 154
	Step 0: mean loss = 0.0306
	Step 50: mean loss = 0.0288
	Step 100: mean loss = 0.0283
	Step 150: mean loss = 0.0279

	Loss on validation set after epoch 154: 0.0268

Epoch 155
	Step 0: mean loss = 0.0242
	Step 50: mean loss = 0.0256
	Step 100: mean loss = 0.0253
	Step 150: mean loss = 0.0251

	Loss on validation set after epoch 155: 0.0239

Model from epoch 145 was selected by early stopping.
Training process will be stopped now.
Deleted temporary files in ../data/trained_models/temp_01-09-09-29-59/
Location of saved model: ../data/trained_models/selected_4_01-09-09-29-59/ 

Adding feature wise convolutions with 32 filters per feature, 3 kernels and 1 strides ...
Adding feature wise convolutions with 1 filters per feature, 3 kernels and 1 strides ...
Adding feature based graph attention layer ...
Adding time based graph attention layer ...
Adding GRU layer with 256 units ...
Adding GRU layer with 61 units ...
Adding GRU layer to forecasting model with 256 units ...
Adding VAE as reconstruction model with dimensions 3072 & 1536 and ...
The RBM reconstructs the output of the gru layer.

Grid search running in AD and FPD selection mode.
The following hyperparameters will not be evaluated:
si_mode
si_parameter

Testing 13200 combinations via grid search 
for model selected_4_01-09-09-29-59/ on the validation dataset. 


Top 50 combinations tested:
      gamma  single_timestamp_a.. affected_timestamp..  unaffected_compone..                         relevance_mapping    AD F1     AD F2  AD TPR   AD Prec    AD ACC  AD TNR  AD FPR  SI/ST AVG-HR@100%  SI/ST AVG-HR@150%  SI/ST AVG-HR@K  SI/ST F1  SI/ST TPR  SI/ST ACC
Comb                                                                                                                                                                                                                                                                       
0       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
1       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
2       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
3       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
4       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
5       0.2                  0.22                   90                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
6       0.2                  0.22                   90                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
7       0.2                  0.22                   90                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
8       0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
9       0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
10      0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
11      0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
12      0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
13      0.2                  0.22                   90                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
14      0.2                  0.22                   90                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
15      0.2                  0.22                   90                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
16      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
17      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
18      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
19      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
20      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
21      0.2                  0.22                   90                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
22      0.2                  0.22                   90                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
23      0.2                  0.22                   90                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
24      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
25      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
26      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
27      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
28      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
29      0.2                  0.22                   90                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
30      0.2                  0.22                   90                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
31      0.2                  0.22                   90                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
32      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
33      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
34      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
35      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
36      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
37      0.2                  0.22                   90                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
38      0.2                  0.22                   90                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
39      0.2                  0.22                   90                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
40      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
41      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
42      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
43      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
44      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
45      0.2                  0.22                  100                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
46      0.2                  0.22                  100                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
47      0.2                  0.22                  100                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
48      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
49      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
50      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
51      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
52      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
53      0.2                  0.22                  100                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
54      0.2                  0.22                  100                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
55      0.2                  0.22                  100                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
56      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
57      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
58      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
59      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
60      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
61      0.2                  0.22                  100                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
62      0.2                  0.22                  100                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
63      0.2                  0.22                  100                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
64      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
65      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
66      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
67      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
68      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
69      0.2                  0.22                  100                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
70      0.2                  0.22                  100                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
71      0.2                  0.22                  100                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
72      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
73      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
74      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
75      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
76      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
77      0.2                  0.22                  100                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
78      0.2                  0.22                  100                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
79      0.2                  0.22                  100                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
80      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
81      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
82      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
83      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
84      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
85      0.2                  0.22                  105                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
86      0.2                  0.22                  105                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
87      0.2                  0.22                  105                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
88      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
89      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
90      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
91      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
92      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
93      0.2                  0.22                  105                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
94      0.2                  0.22                  105                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
95      0.2                  0.22                  105                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
96      0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
97      0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
98      0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
99      0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
100     0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
101     0.2                  0.22                  105                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
102     0.2                  0.22                  105                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
103     0.2                  0.22                  105                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
104     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
105     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
106     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
107     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
108     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
109     0.2                  0.22                  105                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
110     0.2                  0.22                  105                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
111     0.2                  0.22                  105                  0.20  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
112     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
113     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
114     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
115     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
116     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
117     0.2                  0.22                  105                  0.25  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
118     0.2                  0.22                  105                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
119     0.2                  0.22                  105                  0.25  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
120     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
121     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
122     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
123     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
124     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
125     0.2                  0.22                  110                  0.05  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
126     0.2                  0.22                  110                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
127     0.2                  0.22                  110                  0.05  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
128     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
129     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
130     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
131     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
132     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
133     0.2                  0.22                  110                  0.10  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
134     0.2                  0.22                  110                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
135     0.2                  0.22                  110                  0.10  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
136     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
137     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
138     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
139     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
140     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
141     0.2                  0.22                  110                  0.15  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
142     0.2                  0.22                  110                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.012308  0.006154   0.006154   0.847101
143     0.2                  0.22                  110                  0.15  {'h': 0.5, 'm': 1.0, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
144     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 1.0, 'l': 1.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154
145     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 1.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.006154       NaN   0.000000   0.846154
146     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 0.0, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
147     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.0, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
148     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.3}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.000000       NaN   0.000000   0.846154
149     0.2                  0.22                  110                  0.20  {'h': 1.0, 'm': 0.5, 'l': 0.3, 'e': 0.0}  0.31941  0.539867     1.0  0.190058  0.190058     0.0     1.0           0.045031           0.065643        0.003077       NaN   0.000000   0.846154

Full result output for the best combination:
                 #Examples   TP    FP  TN  FN       ACC  FNR  TNR  FPR  TPR      Prec       F1        F2  AVG # affected
Component                                                                                                               
no_failure            1385    0  1385   0   0  0.000000  NaN  0.0  1.0  NaN  0.000000      NaN       NaN      460.644043
txt15_i1                 5    5     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      498.200000
txt15_i3                 5    5     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      478.600000
txt15_conveyor           3    3     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      484.333333
txt15_m1               160  160     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      485.462500
txt15_pl                 9    9     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      471.777778
txt16_i3                 4    4     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      475.750000
txt16_conveyor           8    8     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      467.750000
txt16_m3                65   65     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      486.246154
txt16_turntable          2    2     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      478.000000
txt17_i1                16   16     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      470.062500
txt17_pl                14   14     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      489.714286
txt18_pl                28   28     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      443.071429
txt19_i4                 6    6     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      474.000000
combined              1710  325  1385   0   0  0.190058  0.0  0.0  1.0  1.0  0.190058  0.31941  0.539867      464.376023

                 #Examples   TP    FP  TN  FN       ACC  FNR  TNR  FPR  TPR      Prec       F1        F2  AVG # affected
Component                                                                                                               
no_failure            1385    0  1385   0   0  0.000000  NaN  0.0  1.0  NaN  0.000000      NaN       NaN      460.644043
txt15_i1                 5    5     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      498.200000
txt15_i3                 5    5     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      478.600000
txt15_conveyor           3    3     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      484.333333
txt15_m1               160  160     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      485.462500
txt15_pl                 9    9     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      471.777778
txt16_i3                 4    4     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      475.750000
txt16_conveyor           8    8     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      467.750000
txt16_m3                65   65     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      486.246154
txt16_turntable          2    2     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      478.000000
txt17_i1                16   16     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      470.062500
txt17_pl                14   14     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      489.714286
txt18_pl                28   28     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      443.071429
txt19_i4                 6    6     0   0   0  1.000000  0.0  NaN  NaN  1.0  1.000000  1.00000  1.000000      474.000000
combined              1710  325  1385   0   0  0.190058  0.0  0.0  1.0  1.0  0.190058  0.31941  0.539867      464.376023

Execution time: 268054.8675724929
